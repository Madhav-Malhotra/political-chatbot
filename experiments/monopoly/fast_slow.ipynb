{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monopoly Game Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook runs a simulation of the game Monopoly with multiple agents acting as fast mind and slow mind. \n",
    "\n",
    "It is built [on top of this Monopoly simulator](https://github.com/giogix2/MonopolySimulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Setup\n",
    "\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.3.17)\n",
      "Requirement already satisfied: langchain-chroma>=0.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: langchain-openai>=0.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: langchain>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.3.18)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.10.6)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.3.35)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-openai>=0.2.0->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain>=0.3.0->-r requirements.txt (line 4)) (0.3.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: packaging in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from faiss-cpu>=1.7.0->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: pyproject_hooks in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.45.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.29.3)\n",
      "Requirement already satisfied: sympy in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: filelock in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monopoly simulator\n",
    "from simulator.monosim.player import Player\n",
    "from simulator.monosim.board import get_board, get_roads, get_properties, get_community_chest_cards, get_bank\n",
    "\n",
    "# LangChain\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "\n",
    "# General dependencies\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "from functools import wraps\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define the API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging utilities\n",
    "class StructuredLogger:\n",
    "    \"\"\"\n",
    "    A logger that outputs to TSV files for structured logging of LLM interactions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define all possible message types for documentation\n",
    "    MESSAGE_TYPES = [\n",
    "        \"vectorstore_add\",           # Adding a case to vectorstore\n",
    "        \"vectorstore_retrieve\",      # Retrieving similar cases\n",
    "        \"vectorstore_summarize\",     # Summarizing cached decisions\n",
    "        \"pro_argument_prompt\",       # Input prompt for pro arguments\n",
    "        \"pro_argument_response\",     # Response from pro argument LLM\n",
    "        \"con_argument_prompt\",       # Input prompt for con arguments\n",
    "        \"con_argument_response\",     # Response from con argument LLM\n",
    "        \"judge_prompt\",              # Input prompt for judge\n",
    "        \"judge_response\",            # Response from judge LLM\n",
    "        \"fast_prompt\",               # Input prompt for fast LLM\n",
    "        \"fast_response\",             # Fast LLM respnose\n",
    "        \"slow_prompt\",               # Input prompt for slow LLM\n",
    "        \"slow_response\",             # Slow LLM response\n",
    "\n",
    "        # Monopoly-specific messages\n",
    "        \"property_details\",          # Property information being considered\n",
    "        \"player_stats\",              # Player statistics at decision time\n",
    "        \"default_decision\",          # Default player's decision\n",
    "        \"step_num\",                  # Step number in game\n",
    "        \"game_init\",                 # Game initialization config\n",
    "        \"player_summary\"             # Players' state at decision time\n",
    "    ]\n",
    "\n",
    "    def __init__(self, tsv_filepath: str):\n",
    "        \"\"\"\n",
    "        Initialize the logger with a base filepath.\n",
    "\n",
    "        Args:\n",
    "            tsv_filepath: Filepath for TSV log files (includes timestamp)\n",
    "        \"\"\"\n",
    "        self.tsv_filepath = tsv_filepath\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(self.tsv_filepath), exist_ok=True)\n",
    "\n",
    "        # Initialize TSV file with headers if it doesn't exist\n",
    "        if not os.path.exists(self.tsv_filepath):\n",
    "            with open(self.tsv_filepath, \"w\", newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "                writer = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "                writer.writerow([\"timestamp\", \"message_type\", \"message\"])\n",
    "\n",
    "    def log(self, message_type: str, message_data: Union[str, Dict[str, Any], list[Any], BaseModel]) -> None:\n",
    "        \"\"\"\n",
    "        Log a message to the TSV file.\n",
    "\n",
    "        Args:\n",
    "            message_type: Type of message (one of MESSAGE_TYPES)\n",
    "            message_data: Data to be logged (will be converted to JSON if not already a string)\n",
    "        \"\"\"\n",
    "        if message_type not in self.MESSAGE_TYPES:\n",
    "            raise ValueError(\n",
    "                f\"Invalid message_type: {message_type}. Must be one of {self.MESSAGE_TYPES}\"\n",
    "            )\n",
    "\n",
    "        # Convert message_data to string if it's not already\n",
    "        if isinstance(message_data, BaseModel):\n",
    "            message = json.dumps(message_data.model_dump(), ensure_ascii=False)\n",
    "        elif isinstance(message_data, (dict, list)):\n",
    "            message = json.dumps(message_data, ensure_ascii=False)\n",
    "        else:\n",
    "            message = str(message_data)\n",
    "\n",
    "        timestamp = datetime.now().isoformat()\n",
    "\n",
    "        # Append to TSV file\n",
    "        with open(self.tsv_filepath, \"a\", newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter=\"\\t\", quotechar='`', quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writerow([timestamp, message_type, message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Mind Slow Mind Architecture\n",
    "\n",
    "Setting up output parsers and prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    input_variables=[\"property_details\", \"player_stats\", \"related_decisions\"],\n",
    "    template=\"\"\"\n",
    "    You are a strategic decision-maker playing a game of Monopoly.\n",
    "\n",
    "    Rules of the game:\n",
    "    1. Buying: Players can buy unowned properties they land on for the listed price. Mortgaging or trading properties owned properties is NOT allowed.\n",
    "    2. Building: Rent at a property increases with houses or hotels built. Four houses can be upgraded to a hotel.\n",
    "    3. Rent Bonus: Rent increases if a player owns all three properties of a color.\n",
    "    4. Winning: The last player remaining after others go bankrupt wins.\n",
    "\n",
    "    Your goal:\n",
    "    Decide whether to buy a property in Monopoly. Maximize your chances of winning the game with forward-thinking reasoning.\n",
    "\n",
    "    Past Related Decisions:\n",
    "    {related_decisions}\n",
    "\n",
    "    Current Property Details:\n",
    "    {property_details}\n",
    "\n",
    "    Current Player Details:\n",
    "    {player_stats}\n",
    "\n",
    "    Should the player buy this property? Justify your reasoning briefly.\n",
    "    Then, make your final decision. Output True to buy the property or False to not buy the property.\n",
    "    Finally, output a decimal percentage uncertainty between 0-1 to indicate your uncertainty in the decision.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    reasoning: str = Field(description=\"Your reasoning for the decision\")\n",
    "    decision: bool = Field(description=\"The final decision (True for yes, False for no)\")\n",
    "    uncertainty: float = Field(description=\"Score between 0-1 on how uncertain you are about your vote. 0 if you are completely certain, 1 if you are completely uncertain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vectorstore(timestamp_str: str, game_index: int, \n",
    "                     vectorstore_path: str = \"vectorstore/fastslow\") -> FAISS:\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "    if os.path.exists(vectorstore_path):\n",
    "        # Create archive directory with timestamp and game index\n",
    "        archive_path = f\"{vectorstore_path}/archive/{timestamp_str}/{game_index}\"\n",
    "        os.makedirs(archive_path, exist_ok=True)\n",
    "        \n",
    "        # Move existing files to archive if they exist\n",
    "        for file in ['index.faiss', 'index.pkl']:\n",
    "            src = os.path.join(vectorstore_path, file)\n",
    "            if os.path.exists(src):\n",
    "                dst = os.path.join(archive_path, file)\n",
    "                shutil.move(src, dst)\n",
    "\n",
    "    dummy_doc = [Document(page_content=\"Initialized\")]\n",
    "    vectorstore = FAISS.from_documents(dummy_doc, embedding_model)  \n",
    "    vectorstore.save_local(vectorstore_path)  \n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def retrieve_similar(query: str, vectorstore: FAISS, k: int = 2, logger: Optional[StructuredLogger] = None):\n",
    "    \"\"\"\n",
    "    Retrieve similar documents.\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Query: {query}\")\n",
    "    logging.info(f\"Retrieved similar documents: {json.dumps([doc.model_dump_json() for doc in results], indent=2)}\")\n",
    "    logging.info(\"===\")\n",
    "    \n",
    "    # Log results to structured TSV\n",
    "    if logger:\n",
    "        serializable_results = [\n",
    "            {\"content\": doc.page_content, \"metadata\": doc.metadata, \"query\": query}\n",
    "            for doc in results\n",
    "        ]\n",
    "        logger.log(\"vectorstore_retrieve\", serializable_results)\n",
    "    \n",
    "    return results if results else []\n",
    "\n",
    "def summarize_decisions(results: List[Document], logger: Optional[StructuredLogger] = None) -> Document:\n",
    "    \"\"\"\n",
    "    Summarize the decisions before adding to Vectorstore\n",
    "    \"\"\"\n",
    "    template = PromptTemplate(\n",
    "        input_variables=[\"decisions\"],\n",
    "        template=\"\"\"\n",
    "        You are a strategic decision-maker reviewing past decisions in Monopoly.\n",
    "\n",
    "        Decisions:\n",
    "        {decisions}\n",
    "\n",
    "        Summarize the decisions and reflect on the most important implications for future strategic decisions.\n",
    "        \"\"\"\n",
    "    )\n",
    "    summary_chain = template | ChatOpenAI(model=\"gpt-4o\")\n",
    "    input_decisions = \"\\n\".join([doc.page_content for doc in results])\n",
    "    summary = summary_chain.invoke({\"decisions\": input_decisions}).content\n",
    "\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Input decisions: {input_decisions}\")\n",
    "    logging.info(f\"Summarized decisions: {summary}\")\n",
    "    logging.info(\"===\")\n",
    "\n",
    "    if logger:\n",
    "        logger.log(\"vectorstore_summarize\", {\n",
    "            \"input_decisions\": input_decisions, \n",
    "            \"summary\": summary\n",
    "        })\n",
    "\n",
    "    return Document(page_content=summary)\n",
    "\n",
    "def add_to_vectorstore(case_id: str, \n",
    "                       context: str, \n",
    "                       arguments: str, \n",
    "                       decision: str, \n",
    "                       vectorstore: FAISS, \n",
    "                       CACHED_DECISIONS: list, \n",
    "                       reflection: bool=False, \n",
    "                       vectorstore_path: str = \"vectorstore/fastslow\", \n",
    "                       logger: Optional[StructuredLogger]=None) -> list:\n",
    "    \"\"\"\n",
    "    Add a new document to the vectorstore for future retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    new_case = Document(\n",
    "        page_content=f\"Context: {context}\\nArguments: {arguments}\\nDecision: {decision}\",\n",
    "        metadata={\"case_id\": case_id, \"timestamp\": datetime.now().isoformat()}\n",
    "    )\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Adding document: {json.dumps(new_case.model_dump_json(), indent=2)}\")\n",
    "    logging.info(\"===\")\n",
    "\n",
    "    # Log the operation if logger is provided\n",
    "    if logger:\n",
    "        logger.log(\"vectorstore_add\", new_case)\n",
    "\n",
    "    if reflection:\n",
    "        CACHED_DECISIONS.append(new_case)\n",
    "        if len(CACHED_DECISIONS) >= 3:\n",
    "            summary = summarize_decisions(CACHED_DECISIONS)\n",
    "            vectorstore.add_documents([summary])\n",
    "            vectorstore.save_local(vectorstore_path)\n",
    "            CACHED_DECISIONS.clear()\n",
    "            # Log summary if logger provided\n",
    "            if logger:\n",
    "                logger.log(\"vectorstore_summarize\", {\"num_decisions\": 5, \"summary\": summary.page_content})\n",
    "    else:\n",
    "        vectorstore.add_documents([new_case])\n",
    "        vectorstore.save_local(vectorstore_path)  # Save updates locally\n",
    "\n",
    "    return CACHED_DECISIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buying Properties\n",
    "This function can be modified to get the agent to behave differently when deciding whether to buy a property. The placeholders are just examples of what you can do. Note: you don't need to use all the information available when making a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain output parsing was not working, so using OpenAI's structured outputs\n",
    "def get_openai_response(prompt: str, model: str, max_tokens: int, temperature: float, response_format: BaseModel):\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=response_format,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "def safe_call(func, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error: {e}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_buy(self, dict_property_info : dict) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Edit this function to determine whether the player should buy a property. \n",
    "\n",
    "    Return:\n",
    "    YOUR FUNCTION MUST RETURN \"buy\" (type str) to buy the property \n",
    "    or None (type None) to not buy the property.\n",
    "    \n",
    "    WARNING: I've included exhaustive documentation on all the data you can \n",
    "    use to make this decision. DON'T use all of it; it's mostly irrelevant. \n",
    "\n",
    "    Parameters:\n",
    "    self: useful for accessing the following methods\n",
    "    - self.get_state(): returns player data in a dict with the keys\n",
    "        - cash: the amount of cash the player has\n",
    "        - owned_roads: a list of owned roads\n",
    "        - owned_stations: a list of owned stations\n",
    "        - owned_utilities: a list of owned utilities\n",
    "        - owned_colors: a dict which maps colors to True if the player owns all \n",
    "            properties of that color. Ex: owned_colors['blue'] = True/False\n",
    "        - owned_houses_hotels: a dict which maps property names to the number of \n",
    "            houses/hotels built there. Ex: owned_houses_hotels['Park Place'] = 3\n",
    "        - mortgageable_amount: total mortgageable value of player's properties\n",
    "        WARNING: PROBABLY NOT USEFUL DATA BELOW\n",
    "        - morgaged_roads: a list of mortgaged roads\n",
    "        - mortgaged_stations: a list of mortgaged stations\n",
    "        - mortgaged_utilities: a list of mortgaged utilities\n",
    "        - name: name of player\n",
    "        - number: player number\n",
    "        - position: player's position on the board\n",
    "        - dice_value: the sum of the dice rolled\n",
    "        - jail_count: the number of turns the player has been in jail\n",
    "        - exit_jail: whether the player has exited jail\n",
    "        - free_visit: whether the player is visiting jail for free\n",
    "        - has_lost: whether the player has lost the game\n",
    "    - self._dict_properties[property_name]: returns property info for an \n",
    "    arbitrary property with a dict like dict_property_info below\n",
    "\n",
    "    dict_property_info: Has a dict with info about the property to buy/not buy. \n",
    "        The dict has the following keys:\n",
    "    * name: the name of the property\n",
    "    * belongs_to: the player who owns the property\n",
    "    * price: the price of the property\n",
    "    * rent: the rent of the property\n",
    "    - color: the color of the property\n",
    "    - rent_with_color_set: rent when all properties of same color are owned\n",
    "    * type: the type of property (one of 'road', 'station', 'utility')\n",
    "    - houses_cost: the cost of building a house\n",
    "    - hotels_cost: the cost of building a hotel\n",
    "    - rent_with_X_houses_0_hotels: rent when X = {1, 2, 3, 4} houses are built\n",
    "    - rent_with_4_houses_1_hotels: rent when 4 houses and 1 hotel are built\n",
    "    WARNING: PROBABLY NOT USEFUL DATA BELOW\n",
    "    * mortgage_value: the amount of money earned when mortgaging the property\n",
    "    * unmortgage_value: the amount of money cost to unmortgage the property\n",
    "    * is_mortgaged: whether the property is mortgaged\n",
    "    * board_num: the position of the property on the board\n",
    "    P.S. (* means for all property types, - means for road properties only)\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(f\"Custom buy function called for property: {dict_property_info['name']}\")\n",
    "\n",
    "    # Get model names and parameters from environment variables\n",
    "    primary_model = os.getenv(\"PRIMARY_MODEL_NAME\", \"gpt-4o-mini\")\n",
    "    secondary_model = os.getenv(\"SECONDARY_MODEL_NAME\", \"gpt-4o\")\n",
    "    reflect_before_vectorstore = os.getenv(\"REFLECT_BEFORE_VECTORSTORE\", \"False\").lower() == \"true\"\n",
    "    primary_params = os.getenv(\"PRIMARY_MODEL_PARAMS\", None)\n",
    "    secondary_params = os.getenv(\"SECONDARY_MODEL_PARAMS\", None)\n",
    "    if primary_params:\n",
    "        primary_params = json.loads(primary_params)\n",
    "    if secondary_params:\n",
    "        secondary_params = json.loads(secondary_params)\n",
    "\n",
    "    # Get the logger from environment if available\n",
    "    logger_path = os.getenv(\"LOGGER_PATH\")\n",
    "    logger = None\n",
    "    if logger_path:\n",
    "        logger = StructuredLogger(logger_path)\n",
    "\n",
    "    # currently, no trading. So don't buy property if someone else owns it\n",
    "    if dict_property_info['belongs_to'] != None:\n",
    "        return None\n",
    "\n",
    "    ##################################################\n",
    "    # Step 1: Gather game state and property data\n",
    "    ##################################################\n",
    "    property_details = f\"\"\"\n",
    "    Property Name: {dict_property_info['name']}\n",
    "    Type: {dict_property_info['type']}\n",
    "    Cost: {dict_property_info['price']}\n",
    "    Base Rent: {dict_property_info['rent']}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add specific details for each property type\n",
    "    if dict_property_info['type'] == 'road':\n",
    "        # Calculate number of properties of the same color owned\n",
    "        n_color_properties = 0\n",
    "        for property_name in self.get_state()['owned_roads']:\n",
    "            property_name = property_name.strip().lower()  # normalize name\n",
    "            prop_info = self._dict_properties.get(property_name)  # safe access\n",
    "            if prop_info and prop_info['color'] == dict_property_info['color']:\n",
    "                n_color_properties += 1\n",
    "\n",
    "        property_details += f\"\"\"\n",
    "        Color: {dict_property_info['color']}\n",
    "        Cost of Building a House: {dict_property_info['houses_cost']}\n",
    "        Cost of Building a Hotel: {dict_property_info['hotels_cost']}\n",
    "        Rent with 4 Houses and 1 Hotel: {dict_property_info['rent_with_4_houses_1_hotels']}\n",
    "        Number of {dict_property_info['color']} properties owned: {n_color_properties}\n",
    "        \"\"\"\n",
    "    elif dict_property_info['type'] == 'station':\n",
    "        property_details += f\"\"\"\n",
    "        Number of Stations Owned: {len(self.get_state()['owned_stations'])}\n",
    "        \"\"\"\n",
    "    elif dict_property_info['type'] == 'utility':\n",
    "        property_details += f\"\"\"\n",
    "        Number of Utilities Owned: {len(self.get_state()['owned_utilities'])}\n",
    "        \"\"\"\n",
    "\n",
    "    player_stats = f\"\"\"\n",
    "    Cash: {self.get_state()['cash']}\n",
    "    Owned Roads: {len(self.get_state()['owned_roads'])}\n",
    "    Owned Stations: {len(self.get_state()['owned_stations'])}\n",
    "    Owned Utilities: {len(self.get_state()['owned_utilities'])}\n",
    "    \"\"\"\n",
    "\n",
    "    past_cases = retrieve_similar(\n",
    "        f\"Property details:\\n{property_details}\", \n",
    "        self._vec, \n",
    "        k=2, \n",
    "        logger=logger\n",
    "    )\n",
    "    past_cases_text = \"\\n\".join([case.page_content for case in past_cases])\n",
    "    \n",
    "    ##################################################\n",
    "    # Step 2: LLM generation\n",
    "    ##################################################\n",
    "    UNCERTAINTY_THRESHOLD = 0.2\n",
    "\n",
    "    fast_message = fast_message = template.format(\n",
    "        property_details=property_details,\n",
    "        player_stats=player_stats,\n",
    "        related_decisions=past_cases_text\n",
    "    )\n",
    "    fast_response = safe_call(\n",
    "        get_openai_response,\n",
    "        prompt=fast_message,\n",
    "        model=primary_model,\n",
    "        max_tokens=primary_params.get(\"max_tokens\", 4096),\n",
    "        temperature=primary_params.get(\"temperature\", 1),\n",
    "        response_format=Output\n",
    "    )\n",
    "    decision = fast_response\n",
    "\n",
    "    if fast_response.uncertainty >= UNCERTAINTY_THRESHOLD:\n",
    "        slow_message = template.format(\n",
    "            property_details=property_details,\n",
    "            player_stats=player_stats,\n",
    "            related_decisions=past_cases_text\n",
    "        )\n",
    "        slow_response = safe_call(\n",
    "            get_openai_response,\n",
    "            prompt=slow_message,\n",
    "            model=secondary_model,\n",
    "            max_tokens=secondary_params.get(\"max_tokens\", 4096),\n",
    "            temperature=secondary_params.get(\"temperature\", 1),\n",
    "            response_format=Output\n",
    "        )\n",
    "        decision = slow_response\n",
    "\n",
    "    # ##################################################\n",
    "    # # Step 3: Store the decision in the vectorstore and log\n",
    "    # ##################################################\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Fast input: {fast_message}\")\n",
    "    logging.info(f\"Fast reasoning: {fast_response.reasoning}\")\n",
    "    logging.info(f\"Fast decision: {fast_response.decision}\")\n",
    "    logging.info(f\"Fast uncertainty: {fast_response.uncertainty}\")\n",
    "    logging.info(\"===\")\n",
    "    if fast_response.uncertainty >= UNCERTAINTY_THRESHOLD:\n",
    "        logging.info(f\"Slow input: {slow_message}\")\n",
    "        logging.info(f\"Slow reasoning: {slow_response.reasoning}\")\n",
    "        logging.info(f\"Slow decision: {slow_response.decision}\")\n",
    "        logging.info(f\"Slow uncertainty: {slow_response.uncertainty}\")\n",
    "        logging.info(\"===\")\n",
    "\n",
    "    if logger:\n",
    "        logger.log(\"property_details\", {\n",
    "            \"name\": dict_property_info['name'],\n",
    "            \"type\": dict_property_info['type'],\n",
    "            \"price\": dict_property_info['price'],\n",
    "            \"rent\": dict_property_info['rent'],\n",
    "            \"color\": dict_property_info.get('color', None)\n",
    "        })\n",
    "        logger.log(\"player_stats\", {\n",
    "            \"cash\": self.get_state()['cash'],\n",
    "            \"owned_roads_count\": len(self.get_state()['owned_roads']),\n",
    "            \"owned_stations_count\": len(self.get_state()['owned_stations']),\n",
    "            \"owned_utilities_count\": len(self.get_state()['owned_utilities']),\n",
    "            \"player_name\": self.get_state()['name']\n",
    "        })\n",
    "        logger.log(\"fast_prompt\", fast_message)\n",
    "        logger.log(\"fast_response\", fast_response)\n",
    "        if fast_response.uncertainty >= UNCERTAINTY_THRESHOLD:\n",
    "            logger.log(\"slow_prompt\", slow_message)\n",
    "            logger.log(\"slow_response\", slow_response)\n",
    "\n",
    "    cached_decisions = add_to_vectorstore(\n",
    "        case_id=f\"{dict_property_info['name']}_{self.get_state()['name']}\",\n",
    "        context=f\"Property Details:\\n{property_details}\\nPlayer Stats:\\n{player_stats}\",\n",
    "        arguments=f\"Reasoning: {decision.reasoning}\",\n",
    "        decision=f\"Decision: {\"Buy\" if decision.decision else \"Don't buy\"}\\nUncertainty: {decision.uncertainty}\",\n",
    "        vectorstore=self._vec,\n",
    "        CACHED_DECISIONS=self._cached_decisions,\n",
    "        reflection=reflect_before_vectorstore,\n",
    "        logger=logger\n",
    "    )\n",
    "    self._cached_decisions = cached_decisions\n",
    "    \n",
    "\n",
    "    # Return Decision\n",
    "    return \"buy\" if decision.decision else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend Setup (Do not edit)\n",
    "\n",
    "These are functions that setup a game and let you access the state of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_method(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "\n",
    "        result = func(self, *args, **kwargs)\n",
    "        logging.info(\"===\")\n",
    "        logging.info(f\"Calling {func.__name__} with args: {args}, kwargs: {kwargs}\")\n",
    "        logging.info(f\"{func.__name__} returned: {result}\")\n",
    "        logging.info(\"===\")\n",
    "\n",
    "        log_path = os.getenv(\"LOGGER_PATH\")\n",
    "        if log_path:\n",
    "            logger = StructuredLogger(log_path)\n",
    "            logger.log(\"default_decision\", {\n",
    "                \"args\": args,\n",
    "                \"kwargs\": kwargs,\n",
    "                \"result\": result\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class LoggedPlayer(Player):\n",
    "    @log_method\n",
    "    def buy_or_bid(self, *args, **kwargs):\n",
    "        return super().buy_or_bid(*args, **kwargs)\n",
    "\n",
    "def modify_buy_or_bid(buy) -> str:\n",
    "    return custom_buy\n",
    "\n",
    "class CustomPlayer(Player):\n",
    "    buy_or_bid = modify_buy_or_bid(Player.buy_or_bid)\n",
    "    # Will be overwritten by real vectorstore in init_game function\n",
    "    _vec = None\n",
    "    _cached_decisions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_game(vec: FAISS) -> dict:\n",
    "    \"\"\"\n",
    "    Initializes a game with two players and sets up the bank, board, roads, properties, \n",
    "    and community chest cards.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the following:\n",
    "            - \"bank\": Game's bank object.\n",
    "            - \"board\": Main game board.\n",
    "            - \"roads\": List of road objects.\n",
    "            - \"properties\": List of property objects.\n",
    "            - \"community_chest_cards\": Dictionary of community chest cards.\n",
    "            - \"players\": List of two Player objects, with Player 1 first.\n",
    "    \"\"\"\n",
    "    \n",
    "    bank = get_bank()\n",
    "    board = get_board()\n",
    "    roads = get_roads()\n",
    "    properties = get_properties()\n",
    "    community_chest_cards = get_community_chest_cards()\n",
    "    community_cards_deck = list(community_chest_cards.keys())\n",
    "\n",
    "    # Note how we have one of our players vs. a default player that just buys \n",
    "    # whenever cash is available. We can change this later\n",
    "    player1 = CustomPlayer('Alice', 1, bank, board, roads, properties, community_cards_deck)\n",
    "    player1._vec = vec\n",
    "    player2 = LoggedPlayer('Bob', 2, bank, board, roads, properties, community_cards_deck)\n",
    "    \n",
    "    player1.meet_other_players([player1, player2])\n",
    "    player2.meet_other_players([player1, player2])\n",
    "    \n",
    "    return {\n",
    "        \"bank\": bank,\n",
    "        \"board\": board,\n",
    "        \"roads\": roads,\n",
    "        \"properties\": properties,\n",
    "        \"community_chest_cards\": community_chest_cards,\n",
    "        \"players\": [player1, player2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner(players):\n",
    "    \"\"\"\n",
    "    Determine the winner among players. \n",
    "    \n",
    "    If exactly one player has lost, the other is the winner. \n",
    "    If neither has lost by the time we stop, pick the one with the \n",
    "    greatest net worth (cash + mortgageable_amount) as the winner.\n",
    "    Returns:\n",
    "        winner (Player)\n",
    "    \"\"\"\n",
    "    active_players = [p for p in players if not p.has_lost()]\n",
    "\n",
    "    if len(active_players) == 1:\n",
    "        # Exactly one survivor\n",
    "        return active_players[0]\n",
    "    else:\n",
    "        # More than one still in => compare net worth\n",
    "        # If there's a tie in net worth, we return None\n",
    "        top_player = None\n",
    "        top_net_worth = -1\n",
    "        \n",
    "        for p in active_players:\n",
    "            st = p.get_state()\n",
    "            net_worth = st[\"cash\"] + st[\"mortgageable_amount\"]\n",
    "            if net_worth > top_net_worth:\n",
    "                top_player = p\n",
    "                top_net_worth = net_worth\n",
    "            elif net_worth == top_net_worth:\n",
    "                # tie\n",
    "                top_player = None\n",
    "        \n",
    "        return top_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def players_state(players) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to get a logstring showing all players' states.\n",
    "    \"\"\"\n",
    "\n",
    "    state_obj = []\n",
    "    for player in players:\n",
    "        state_obj += [player.get_state()]\n",
    "    \n",
    "    return json.dumps(state_obj, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    open_ai_key: str,\n",
    "    raw_log_filepath: str,\n",
    "    win_rate_filepath: str,\n",
    "    max_steps_per_game: int = 10,\n",
    "    num_games: int = 10,\n",
    "    reflect_before_vectorstore: bool = False,\n",
    "    primary_model: str = \"gpt-4o-mini\",\n",
    "    primary_model_params: dict = {},\n",
    "    secondary_model: str = \"gpt-4o\",\n",
    "    secondary_model_params: dict = {},\n",
    "    random_seed: int = 42\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run an experiment with the given parameters, ensuring ALL data are saved.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    open_ai_key : str\n",
    "        The OpenAI API key.\n",
    "    raw_log_filepath : str\n",
    "        Base filepath to save outputs from all LLM completions and vectorstore \n",
    "        search results for each game. We'll append `_game{i}_timestamp.log`.\n",
    "    win_rate_filepath : str\n",
    "        Base filepath to save CSV of game outcomes (two columns: \n",
    "        'raw_log_filepath' and 'custom_agent_won'). We'll append `_timestamp.csv`.\n",
    "    max_steps_per_game : int, optional\n",
    "        The maximum number of steps per game.\n",
    "    num_games : int, optional\n",
    "        The number of games to play to get the average win rate.\n",
    "    reflect_before_vectorstore : bool, optional\n",
    "        Whether to reflect and summarize data before adding past context to \n",
    "        vectorstore.\n",
    "    primary_model : str, optional\n",
    "        Name of the primary fast LLM to use (for lawyer chains).\n",
    "    primary_model_params : dict, optional\n",
    "        Key-value pairs for the primary LLM (e.g. {\"temperature\": 0.7}).\n",
    "    secondary_model : str, optional\n",
    "        Name of the secondary slow LLM to use (for judge chains).\n",
    "    secondary_model_params : dict, optional\n",
    "        Key-value pairs for the secondary LLM (e.g. {\"temperature\": 0.0}).\n",
    "    \"\"\"\n",
    "\n",
    "    # Export model settings to environment variables\n",
    "    os.environ[\"OPENAI_API_KEY\"] = open_ai_key \n",
    "    os.environ[\"PRIMARY_MODEL_NAME\"] = primary_model\n",
    "    os.environ[\"SECONDARY_MODEL_NAME\"] = secondary_model\n",
    "    os.environ[\"REFLECT_BEFORE_VECTORSTORE\"] = str(reflect_before_vectorstore)\n",
    "\n",
    "    if primary_model_params:\n",
    "        os.environ[\"PRIMARY_MODEL_PARAMS\"] = json.dumps(primary_model_params)\n",
    "    if secondary_model_params:\n",
    "        os.environ[\"SECONDARY_MODEL_PARAMS\"] = json.dumps(secondary_model_params)\n",
    "\n",
    "    # Prepare path for CSV that tracks win/loss for each game\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_win_rate_csv = f\"logs/fastslow/{random_seed}/{timestamp_str}/{win_rate_filepath}.csv\"\n",
    "\n",
    "    # Ensure the directory exists for the CSV\n",
    "    os.makedirs(os.path.dirname(final_win_rate_csv), exist_ok=True)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Run multiple games\n",
    "    # -------------------------------------------------------------------------\n",
    "    with open(final_win_rate_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        writer.writerow([\"raw_log_filepath\", \"custom_agent_won\"])\n",
    "\n",
    "        for game_index in range(num_games):\n",
    "            print(f\"\\nStarting game {game_index}\")\n",
    "\n",
    "            # Archive and reset the vectorstore for each game\n",
    "            vec = init_vectorstore(timestamp_str, game_index)\n",
    "\n",
    "            # We'll log everything into a single .log file for this game\n",
    "            game_log_file = f\"logs/fastslow/{random_seed}/{timestamp_str}/{raw_log_filepath}_game{game_index}.log\"\n",
    "            game_tsv_file = f\"logs/fastslow/{random_seed}/{timestamp_str}/{raw_log_filepath}_game{game_index}.tsv\"\n",
    "            os.makedirs(os.path.dirname(game_log_file), exist_ok=True)\n",
    "            os.makedirs(os.path.dirname(game_tsv_file), exist_ok=True)\n",
    "\n",
    "            os.environ[\"LOGGER_PATH\"] = game_tsv_file\n",
    "            logger = StructuredLogger(game_tsv_file)\n",
    "            \n",
    "            logging.basicConfig(\n",
    "                filename=game_log_file, level=logging.INFO, force=True,\n",
    "                format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "            )\n",
    "            config = {\n",
    "                \"max_steps_per_game\": max_steps_per_game,\n",
    "                \"num_games\": num_games,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"primary_model\": primary_model,\n",
    "                \"primary_model_params\": primary_model_params,\n",
    "                \"secondary_model\": secondary_model,\n",
    "                \"secondary_model_params\": secondary_model_params,\n",
    "            }\n",
    "            logging.info(f\"Starting game {game_index} with config: {config}\")\n",
    "            logger.log(\"game_init\", config)\n",
    "            \n",
    "            game_data = initialize_game(vec)\n",
    "            players = game_data[\"players\"]\n",
    "\n",
    "            # Run up to max_steps_per_game\n",
    "            step = 0\n",
    "            while step < max_steps_per_game:\n",
    "                # Logging progress\n",
    "                print(step, end=\", \")\n",
    "                if (step + 1) % 30 == 0:\n",
    "                    print(\"\")\n",
    "                logging.info(\"===\")\n",
    "                logging.info(f\"Step {step}\")\n",
    "                logging.info(\"===\")\n",
    "                logger.log(\"step_num\", step)\n",
    "                logger.log(\"player_summary\", players_state(players))\n",
    "\n",
    "                # Check if the game already ended\n",
    "                if any(p.has_lost() for p in players):\n",
    "                    break\n",
    "\n",
    "                for p in players:\n",
    "                    if not p.has_lost():\n",
    "                        p.play()\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            # Determine winner\n",
    "            winner = get_winner(players)\n",
    "\n",
    "            # Check if the winner is our custom agent (player1 in this setup)\n",
    "            custom_agent = players[0]\n",
    "            custom_agent_won = (winner == custom_agent)\n",
    "\n",
    "            # Write to CSV\n",
    "            writer.writerow([game_log_file, str(custom_agent_won)])\n",
    "\n",
    "    print(f\"\\nAll {num_games} games complete. Results saved to: {final_win_rate_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting game 0\n",
      "0, 1, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopen_ai_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_log_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfastslow_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwin_rate_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfastslow_win_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps_per_game\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_games\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreflect_before_vectorstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_model_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecondary_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecondary_model_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[134], line 126\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(open_ai_key, raw_log_filepath, win_rate_filepath, max_steps_per_game, num_games, reflect_before_vectorstore, primary_model, primary_model_params, secondary_model, secondary_model_params, random_seed)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m players:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mhas_lost():\n\u001b[0;32m--> 126\u001b[0m             \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Determine winner\u001b[39;00m\n",
      "File \u001b[0;32m~/political-chatbot/experiments/monopoly/simulator/monosim/player.py:1083\u001b[0m, in \u001b[0;36mPlayer.play\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m property_owner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhave_enough_money(dict_property_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m-> 1083\u001b[0m         buy_bid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuy_or_bid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_property_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m buy_bid \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m board_cell_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroad\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuy(dict_property_info, property_name)\n",
      "Cell \u001b[0;32mIn[129], line 160\u001b[0m, in \u001b[0;36mcustom_buy\u001b[0;34m(self, dict_property_info)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fast_response\u001b[38;5;241m.\u001b[39muncertainty \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m UNCERTAINTY_THRESHOLD:\n\u001b[1;32m    155\u001b[0m     slow_message \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    156\u001b[0m         property_details\u001b[38;5;241m=\u001b[39mproperty_details,\n\u001b[1;32m    157\u001b[0m         player_stats\u001b[38;5;241m=\u001b[39mplayer_stats,\n\u001b[1;32m    158\u001b[0m         related_decisions\u001b[38;5;241m=\u001b[39mpast_cases_text\n\u001b[1;32m    159\u001b[0m     )\n\u001b[0;32m--> 160\u001b[0m     slow_response \u001b[38;5;241m=\u001b[39m \u001b[43msafe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_openai_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslow_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecondary_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecondary_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecondary_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOutput\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     decision \u001b[38;5;241m=\u001b[39m slow_response\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# ##################################################\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# # Step 3: Store the decision in the vectorstore and log\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# ##################################################\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[128], line 19\u001b[0m, in \u001b[0;36msafe_call\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_call\u001b[39m(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[128], line 5\u001b[0m, in \u001b[0;36mget_openai_response\u001b[0;34m(prompt, model, max_tokens, temperature, response_format)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_openai_response\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m, max_tokens: \u001b[38;5;28mint\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m, response_format: BaseModel):\n\u001b[1;32m      3\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m----> 5\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mparsed\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/openai/resources/beta/chat/completions.py:161\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    156\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    157\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    158\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    159\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/openai/_base_client.py:1003\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1000\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1009\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/political-chatbot/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    open_ai_key=openai_key,\n",
    "    raw_log_filepath=\"fastslow_raw\",\n",
    "    win_rate_filepath=\"fastslow_win_rate\",\n",
    "    max_steps_per_game=200,\n",
    "    num_games=20,\n",
    "    reflect_before_vectorstore=True,\n",
    "    primary_model=\"gpt-4o-mini\",\n",
    "    primary_model_params={\"temperature\": 1.0, \"max_tokens\": 2048},\n",
    "    secondary_model=\"gpt-4o\",\n",
    "    secondary_model_params={\"temperature\": 1.0, \"max_tokens\": 2048},\n",
    "    random_seed = 42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
