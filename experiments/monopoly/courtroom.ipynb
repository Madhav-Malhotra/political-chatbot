{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monopoly Game Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook runs a simulation of the game Monopoly with multiple agents. It is built on top of this simulator: \n",
    "\n",
    "[Github Repo]( https://github.com/giogix2/MonopolySimulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.3.17)\n",
      "Requirement already satisfied: langchain-chroma>=0.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: langchain-openai>=0.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: langchain>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.3.18)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.10.6)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.10.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.3.35)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-openai>=0.2.0->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain>=0.3.0->-r requirements.txt (line 4)) (0.3.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: packaging in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from faiss-cpu>=1.7.0->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.0->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.3.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.2.0->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: pyproject_hooks in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.45.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community>=0.3.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.29.3)\n",
      "Requirement already satisfied: sympy in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: filelock in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/mdvmlhtr/political-chatbot/.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma>=0.1.0->-r requirements.txt (line 2)) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monopoly simulator\n",
    "from simulator.monosim.player import Player\n",
    "from simulator.monosim.board import get_board, get_roads, get_properties, get_community_chest_cards, get_bank\n",
    "\n",
    "# LangChain\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "\n",
    "# General dependencies\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "from functools import wraps\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define the API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging utilities\n",
    "class StructuredLogger:\n",
    "    \"\"\"\n",
    "    A logger that outputs to TSV files for structured logging of LLM interactions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define all possible message types for documentation\n",
    "    MESSAGE_TYPES = [\n",
    "        \"vectorstore_add\",           # Adding a case to vectorstore\n",
    "        \"vectorstore_retrieve\",      # Retrieving similar cases\n",
    "        \"vectorstore_summarize\",     # Summarizing cached decisions\n",
    "        \"pro_argument_prompt\",       # Input prompt for pro arguments\n",
    "        \"pro_argument_response\",     # Response from pro argument LLM\n",
    "        \"con_argument_prompt\",       # Input prompt for con arguments\n",
    "        \"con_argument_response\",     # Response from con argument LLM\n",
    "        \"judge_prompt\",              # Input prompt for judge\n",
    "        \"judge_response\",            # Response from judge LLM\n",
    "        \"fast_prompt\",               # Input prompt for fast LLM\n",
    "        \"fast_response\",             # Fast LLM respnose\n",
    "        \"slow_prompt\",               # Input prompt for slow LLM\n",
    "        \"slow_response\",             # Slow LLM response\n",
    "\n",
    "        # Monopoly-specific messages\n",
    "        \"property_details\",          # Property information being considered\n",
    "        \"player_stats\",              # Player statistics at decision time\n",
    "        \"default_decision\",          # Default player's decision\n",
    "        \"step_num\",                  # Step number in game\n",
    "        \"game_init\",                 # Game initialization config\n",
    "        \"player_summary\"             # Players' state at decision time\n",
    "    ]\n",
    "\n",
    "    def __init__(self, tsv_filepath: str):\n",
    "        \"\"\"\n",
    "        Initialize the logger with a base filepath.\n",
    "\n",
    "        Args:\n",
    "            tsv_filepath: Filepath for TSV log files (includes timestamp)\n",
    "        \"\"\"\n",
    "        self.tsv_filepath = tsv_filepath\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(self.tsv_filepath), exist_ok=True)\n",
    "\n",
    "        # Initialize TSV file with headers if it doesn't exist\n",
    "        if not os.path.exists(self.tsv_filepath):\n",
    "            with open(self.tsv_filepath, \"w\", newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "                writer = csv.writer(tsvfile, delimiter=\"\\t\")\n",
    "                writer.writerow([\"timestamp\", \"message_type\", \"message\"])\n",
    "\n",
    "    def log(self, message_type: str, message_data: Union[str, Dict[str, Any], list[Any], BaseModel]) -> None:\n",
    "        \"\"\"\n",
    "        Log a message to the TSV file.\n",
    "\n",
    "        Args:\n",
    "            message_type: Type of message (one of MESSAGE_TYPES)\n",
    "            message_data: Data to be logged (will be converted to JSON if not already a string)\n",
    "        \"\"\"\n",
    "        if message_type not in self.MESSAGE_TYPES:\n",
    "            raise ValueError(\n",
    "                f\"Invalid message_type: {message_type}. Must be one of {self.MESSAGE_TYPES}\"\n",
    "            )\n",
    "\n",
    "        # Convert message_data to string if it's not already\n",
    "        if isinstance(message_data, BaseModel):\n",
    "            message = json.dumps(message_data.model_dump(), ensure_ascii=False)\n",
    "        elif isinstance(message_data, (dict, list)):\n",
    "            message = json.dumps(message_data, ensure_ascii=False)\n",
    "        else:\n",
    "            message = str(message_data)\n",
    "\n",
    "        timestamp = datetime.now().isoformat()\n",
    "\n",
    "        # Append to TSV file\n",
    "        with open(self.tsv_filepath, \"a\", newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter=\"\\t\", quotechar='`', quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writerow([timestamp, message_type, message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courtroom Architecture\n",
    "\n",
    "The following three chains will generate arguments for, against, and a final decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lawyer Pro: Argument for buying the property\n",
    "pro_prompt = PromptTemplate(\n",
    "    input_variables=[\"property_details\", \"player_stats\", \"related_decisions\"],\n",
    "    template=\"\"\"\n",
    "    You are a strategic decision-maker playing a game of Monopoly.\n",
    "\n",
    "    Rules of the game:\n",
    "    1. Buying: Players can buy unowned properties they land on for the listed price. Mortgaging or trading properties owned properties is NOT allowed.\n",
    "    2. Building: Rent at a property increases with houses or hotels built. Four houses can be upgraded to a hotel.\n",
    "    3. Rent Bonus: Rent increases if a player owns all three properties of a color.\n",
    "    4. Winning: The last player remaining after others go bankrupt wins.\n",
    "\n",
    "    Your goal:\n",
    "    You are arguing FOR the decision to buy a property in Monopoly.\n",
    "\n",
    "    Past Related Decisions:\n",
    "    {related_decisions}\n",
    "\n",
    "    Current Property Details:\n",
    "    {property_details}\n",
    "\n",
    "    Current Player Details:\n",
    "    {player_stats}\n",
    "\n",
    "    Argue FOR buying the Current Property in bullet-point format. Use at most 3 bullets.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Lawyer Con: Argument against buying the property\n",
    "con_prompt = PromptTemplate(\n",
    "    input_variables=[\"property_details\", \"player_stats\", \"related_decisions\"],\n",
    "    template=\"\"\"\n",
    "    You are a strategic decision-maker playing a game of Monopoly.\n",
    "\n",
    "    Rules of the game:\n",
    "    1. Buying: Players can buy unowned properties they land on for the listed price. Mortgaging or trading properties owned properties is NOT allowed.\n",
    "    2. Building: Rent at a property increases with houses or hotels built. Four houses can be upgraded to a hotel.\n",
    "    3. Rent Bonus: Rent increases if a player owns all three properties of a color.\n",
    "    4. Winning: The last player remaining after others go bankrupt wins.\n",
    "    \n",
    "    Your goal:\n",
    "    You are arguing AGAINST the decision to buy a property in Monopoly.\n",
    "\n",
    "    Past Related Decisions:\n",
    "    {related_decisions}\n",
    "\n",
    "    Current Property Details:\n",
    "    {property_details}\n",
    "\n",
    "    Current Player Details:\n",
    "    {player_stats}\n",
    "\n",
    "    Argue AGAINST buying the Current Property in bullet-point format. Use at most 3 bullets.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Judge: Final decision based on arguments\n",
    "judge_prompt = PromptTemplate(\n",
    "    input_variables=[\"property_details\", \"player_stats\", \"arguments_for\", \"arguments_against\"],\n",
    "    template=\"\"\"\n",
    "    You are a strategic decision-maker playing a game of Monopoly.\n",
    "\n",
    "    Rules of the game:\n",
    "    1. Buying: Players can buy unowned properties they land on for the listed price. Mortgaging or trading properties owned properties is NOT allowed.\n",
    "    2. Building: Rent at a property increases with houses or hotels built. Four houses can be upgraded to a hotel.\n",
    "    3. Rent Bonus: Rent increases if a player owns all three properties of a color.\n",
    "    4. Winning: The last player remaining after others go bankrupt wins.\n",
    "    \n",
    "    Your goal:\n",
    "    You are judging arguments to decide whether to buy a property in Monopoly. Maximize your chances of winning the game with forward-thinking reasoning.\n",
    "    \n",
    "    Property Details:\n",
    "    {property_details}\n",
    "\n",
    "    Player Details:\n",
    "    {player_stats}\n",
    "\n",
    "    Argument FOR buying the property:\n",
    "    {arguments_for}\n",
    "\n",
    "    Argument AGAINST buying the property:\n",
    "    {arguments_against}\n",
    "\n",
    "    Should the player buy this property? Justify your reasoning briefly.\n",
    "    Then, make your final decision. Output True to buy the property or False to not buy the property. \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also add output parsers to interpret the decisions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Argument(BaseModel):\n",
    "    argument: str = Field(description=\"The argument for or against buying the property\")\n",
    "\n",
    "class JudgeDecision(BaseModel):\n",
    "    reasoning: str = Field(description=\"The reasoning behind your decision\")\n",
    "    decision: bool = Field(description=\"True to buy property, False to not buy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vectorstore(timestamp_str: str, game_index: int, \n",
    "                     vectorstore_path: str = \"vectorstore/fastslow\") -> FAISS:\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "    if os.path.exists(vectorstore_path):\n",
    "        # Create archive directory with timestamp and game index\n",
    "        archive_path = f\"{vectorstore_path}/archive/{timestamp_str}/{game_index}\"\n",
    "        os.makedirs(archive_path, exist_ok=True)\n",
    "        \n",
    "        # Move existing files to archive if they exist\n",
    "        for file in ['index.faiss', 'index.pkl']:\n",
    "            src = os.path.join(vectorstore_path, file)\n",
    "            if os.path.exists(src):\n",
    "                dst = os.path.join(archive_path, file)\n",
    "                shutil.move(src, dst)\n",
    "\n",
    "    dummy_doc = [Document(page_content=\"Initialized\")]\n",
    "    vectorstore = FAISS.from_documents(dummy_doc, embedding_model)  \n",
    "    vectorstore.save_local(vectorstore_path)  \n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def retrieve_similar(query: str, vectorstore: FAISS, k: int = 2, logger: Optional[StructuredLogger] = None):\n",
    "    \"\"\"\n",
    "    Retrieve similar documents.\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Query: {query}\")\n",
    "    logging.info(f\"Retrieved similar documents: {json.dumps([doc.model_dump_json() for doc in results], indent=2)}\")\n",
    "    logging.info(\"===\")\n",
    "    \n",
    "    # Log results to structured TSV\n",
    "    if logger:\n",
    "        serializable_results = [\n",
    "            {\"content\": doc.page_content, \"metadata\": doc.metadata, \"query\": query}\n",
    "            for doc in results\n",
    "        ]\n",
    "        logger.log(\"vectorstore_retrieve\", serializable_results)\n",
    "    \n",
    "    return results if results else []\n",
    "\n",
    "def summarize_decisions(results: List[Document], logger: Optional[StructuredLogger] = None) -> Document:\n",
    "    \"\"\"\n",
    "    Summarize the decisions before adding to Vectorstore\n",
    "    \"\"\"\n",
    "    template = PromptTemplate(\n",
    "        input_variables=[\"decisions\"],\n",
    "        template=\"\"\"\n",
    "        You are a strategic decision-maker reviewing past decisions in Monopoly.\n",
    "\n",
    "        Decisions:\n",
    "        {decisions}\n",
    "\n",
    "        Summarize the decisions and reflect on the most important implications for future strategic decisions.\n",
    "        \"\"\"\n",
    "    )\n",
    "    summary_chain = template | ChatOpenAI(model=\"gpt-4o\")\n",
    "    input_decisions = \"\\n\".join([doc.page_content for doc in results])\n",
    "    summary = summary_chain.invoke({\"decisions\": input_decisions}).content\n",
    "\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Input decisions: {input_decisions}\")\n",
    "    logging.info(f\"Summarized decisions: {summary}\")\n",
    "    logging.info(\"===\")\n",
    "\n",
    "    if logger:\n",
    "        logger.log(\"vectorstore_summarize\", {\n",
    "            \"input_decisions\": input_decisions, \n",
    "            \"summary\": summary\n",
    "        })\n",
    "\n",
    "    return Document(page_content=summary)\n",
    "\n",
    "def add_to_vectorstore(case_id: str, \n",
    "                       context: str, \n",
    "                       arguments: str, \n",
    "                       decision: str, \n",
    "                       vectorstore: FAISS, \n",
    "                       CACHED_DECISIONS: list, \n",
    "                       reflection: bool=False, \n",
    "                       vectorstore_path: str = \"vectorstore/fastslow\", \n",
    "                       logger: Optional[StructuredLogger]=None) -> list:\n",
    "    \"\"\"\n",
    "    Add a new document to the vectorstore for future retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    new_case = Document(\n",
    "        page_content=f\"Context: {context}\\nArguments: {arguments}\\nDecision: {decision}\",\n",
    "        metadata={\"case_id\": case_id, \"timestamp\": datetime.now().isoformat()}\n",
    "    )\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Adding document: {json.dumps(new_case.model_dump_json(), indent=2)}\")\n",
    "    logging.info(\"===\")\n",
    "\n",
    "    # Log the operation if logger is provided\n",
    "    if logger:\n",
    "        logger.log(\"vectorstore_add\", new_case)\n",
    "\n",
    "    if reflection:\n",
    "        CACHED_DECISIONS.append(new_case)\n",
    "        if len(CACHED_DECISIONS) >= 3:\n",
    "            summary = summarize_decisions(CACHED_DECISIONS)\n",
    "            vectorstore.add_documents([summary])\n",
    "            vectorstore.save_local(vectorstore_path)\n",
    "            CACHED_DECISIONS.clear()\n",
    "            # Log summary if logger provided\n",
    "            if logger:\n",
    "                logger.log(\"vectorstore_summarize\", {\"num_decisions\": 5, \"summary\": summary.page_content})\n",
    "    else:\n",
    "        vectorstore.add_documents([new_case])\n",
    "        vectorstore.save_local(vectorstore_path)  # Save updates locally\n",
    "\n",
    "    return CACHED_DECISIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buying Properties\n",
    "This function can be modified to get the agent to behave differently when deciding whether to buy a property. The placeholders are just examples of what you can do. Note: you don't need to use all the information available when making a decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain output parsing was not working, so using OpenAI's structured outputs\n",
    "def get_openai_response(prompt: str, model: str, max_tokens: int, temperature: float, response_format: BaseModel):\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=response_format,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "def safe_call(func, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error: {e}\")\n",
    "            print(f\"Error: {e}\")\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_buy(self, dict_property_info : dict) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Edit this function to determine whether the player should buy a property. \n",
    "\n",
    "    Return:\n",
    "    YOUR FUNCTION MUST RETURN \"buy\" (type str) to buy the property \n",
    "    or None (type None) to not buy the property.\n",
    "    \n",
    "    WARNING: I've included exhaustive documentation on all the data you can \n",
    "    use to make this decision. DON'T use all of it; it's mostly irrelevant. \n",
    "\n",
    "    Parameters:\n",
    "    self: useful for accessing the following methods\n",
    "    - self.get_state(): returns player data in a dict with the keys\n",
    "        - cash: the amount of cash the player has\n",
    "        - owned_roads: a list of owned roads\n",
    "        - owned_stations: a list of owned stations\n",
    "        - owned_utilities: a list of owned utilities\n",
    "        - owned_colors: a dict which maps colors to True if the player owns all \n",
    "            properties of that color. Ex: owned_colors['blue'] = True/False\n",
    "        - owned_houses_hotels: a dict which maps property names to the number of \n",
    "            houses/hotels built there. Ex: owned_houses_hotels['Park Place'] = 3\n",
    "        - mortgageable_amount: total mortgageable value of player's properties\n",
    "        WARNING: PROBABLY NOT USEFUL DATA BELOW\n",
    "        - morgaged_roads: a list of mortgaged roads\n",
    "        - mortgaged_stations: a list of mortgaged stations\n",
    "        - mortgaged_utilities: a list of mortgaged utilities\n",
    "        - name: name of player\n",
    "        - number: player number\n",
    "        - position: player's position on the board\n",
    "        - dice_value: the sum of the dice rolled\n",
    "        - jail_count: the number of turns the player has been in jail\n",
    "        - exit_jail: whether the player has exited jail\n",
    "        - free_visit: whether the player is visiting jail for free\n",
    "        - has_lost: whether the player has lost the game\n",
    "    - self._dict_properties[property_name]: returns property info for an \n",
    "    arbitrary property with a dict like dict_property_info below\n",
    "\n",
    "    dict_property_info: Has a dict with info about the property to buy/not buy. \n",
    "        The dict has the following keys:\n",
    "    * name: the name of the property\n",
    "    * belongs_to: the player who owns the property\n",
    "    * price: the price of the property\n",
    "    * rent: the rent of the property\n",
    "    - color: the color of the property\n",
    "    - rent_with_color_set: rent when all properties of same color are owned\n",
    "    * type: the type of property (one of 'road', 'station', 'utility')\n",
    "    - houses_cost: the cost of building a house\n",
    "    - hotels_cost: the cost of building a hotel\n",
    "    - rent_with_X_houses_0_hotels: rent when X = {1, 2, 3, 4} houses are built\n",
    "    - rent_with_4_houses_1_hotels: rent when 4 houses and 1 hotel are built\n",
    "    WARNING: PROBABLY NOT USEFUL DATA BELOW\n",
    "    * mortgage_value: the amount of money earned when mortgaging the property\n",
    "    * unmortgage_value: the amount of money cost to unmortgage the property\n",
    "    * is_mortgaged: whether the property is mortgaged\n",
    "    * board_num: the position of the property on the board\n",
    "    P.S. (* means for all property types, - means for road properties only)\n",
    "    \"\"\"\n",
    "    logging.info(f\"Custom buy function called for property: {dict_property_info['name']}\")\n",
    "\n",
    "    # Get model names and parameters from environment variables\n",
    "    primary_model = os.getenv(\"PRIMARY_MODEL_NAME\", \"gpt-4o-mini\")\n",
    "    reflect_before_vectorstore = os.getenv(\"REFLECT_BEFORE_VECTORSTORE\", \"False\").lower() == \"true\"\n",
    "    primary_params = os.getenv(\"PRIMARY_MODEL_PARAMS\", None)\n",
    "    if primary_params:\n",
    "        primary_params = json.loads(primary_params)\n",
    "\n",
    "    # Get the logger from environment if available\n",
    "    logger_path = os.getenv(\"LOGGER_PATH\")\n",
    "    logger = None\n",
    "    if logger_path:\n",
    "        logger = StructuredLogger(logger_path)\n",
    "\n",
    "    # currently, no trading. So don't buy property if someone else owns it\n",
    "    if dict_property_info['belongs_to'] != None:\n",
    "        return None\n",
    "\n",
    "    ##################################################\n",
    "    # Step 1: Gather game state and property data\n",
    "    ##################################################\n",
    "    property_details = f\"\"\"\n",
    "    Property Name: {dict_property_info['name']}\n",
    "    Type: {dict_property_info['type']}\n",
    "    Cost: {dict_property_info['price']}\n",
    "    Base Rent: {dict_property_info['rent']}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add specific details for each property type\n",
    "    if dict_property_info['type'] == 'road':\n",
    "        # Calculate number of properties of the same color owned\n",
    "        n_color_properties = 0\n",
    "        for property_name in self.get_state()['owned_roads']:\n",
    "            property_name = property_name.strip().lower()  # normalize name\n",
    "            prop_info = self._dict_properties.get(property_name)  # safe access\n",
    "            if prop_info and prop_info['color'] == dict_property_info['color']:\n",
    "                n_color_properties += 1\n",
    "\n",
    "        property_details += f\"\"\"\n",
    "        Color: {dict_property_info['color']}\n",
    "        Cost of Building a House: {dict_property_info['houses_cost']}\n",
    "        Cost of Building a Hotel: {dict_property_info['hotels_cost']}\n",
    "        Rent with 4 Houses and 1 Hotel: {dict_property_info['rent_with_4_houses_1_hotels']}\n",
    "        Number of {dict_property_info['color']} properties owned: {n_color_properties}\n",
    "        \"\"\"\n",
    "    elif dict_property_info['type'] == 'station':\n",
    "        property_details += f\"\"\"\n",
    "        Number of Stations Owned: {len(self.get_state()['owned_stations'])}\n",
    "        \"\"\"\n",
    "    elif dict_property_info['type'] == 'utility':\n",
    "        property_details += f\"\"\"\n",
    "        Number of Utilities Owned: {len(self.get_state()['owned_utilities'])}\n",
    "        \"\"\"\n",
    "\n",
    "    player_stats = f\"\"\"\n",
    "    Cash: {self.get_state()['cash']}\n",
    "    Owned Roads: {len(self.get_state()['owned_roads'])}\n",
    "    Owned Stations: {len(self.get_state()['owned_stations'])}\n",
    "    Owned Utilities: {len(self.get_state()['owned_utilities'])}\n",
    "    \"\"\"\n",
    "\n",
    "    past_cases = retrieve_similar(\n",
    "        f\"Property details:\\n{property_details}\", \n",
    "        self._vec, \n",
    "        k=2, \n",
    "        logger=logger\n",
    "    )\n",
    "    past_cases_text = \"\\n\".join([case.page_content for case in past_cases])\n",
    "\n",
    "    ##################################################\n",
    "    # Step 2: LLM generation\n",
    "    ##################################################\n",
    "    pro_message = pro_prompt.format(\n",
    "        property_details=property_details,\n",
    "        player_stats=player_stats,\n",
    "        related_decisions=past_cases_text\n",
    "    )\n",
    "    con_message = con_prompt.format(\n",
    "        property_details=property_details,\n",
    "        player_stats=player_stats,\n",
    "        related_decisions=past_cases_text\n",
    "    ) \n",
    "\n",
    "    arguments_for = safe_call(\n",
    "        get_openai_response,\n",
    "        prompt=pro_message,\n",
    "        model=primary_model,\n",
    "        max_tokens=primary_params.get(\"max_tokens\", 4096),\n",
    "        temperature=primary_params.get(\"temperature\", 1),\n",
    "        response_format=Argument\n",
    "    )\n",
    "\n",
    "    arguments_against = safe_call(\n",
    "        get_openai_response,\n",
    "        prompt=con_message,\n",
    "        model=primary_model,\n",
    "        max_tokens=primary_params.get(\"max_tokens\", 4096),\n",
    "        temperature=primary_params.get(\"temperature\", 1),\n",
    "        response_format=Argument\n",
    "    )\n",
    "\n",
    "    judge_message = judge_prompt.format(\n",
    "        property_details=property_details,\n",
    "        player_stats=player_stats,\n",
    "        arguments_for=arguments_for.argument,\n",
    "        arguments_against=arguments_against.argument\n",
    "    )\n",
    "    decision = safe_call(\n",
    "        get_openai_response,\n",
    "        prompt=judge_message,\n",
    "        model=primary_model,\n",
    "        max_tokens=primary_params.get(\"max_tokens\", 4096),\n",
    "        temperature=primary_params.get(\"temperature\", 1),\n",
    "        response_format=JudgeDecision\n",
    "    )\n",
    "\n",
    "    # ##################################################\n",
    "    # # Step 3: Store the decision in the vectorstore and log\n",
    "    # ##################################################\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Pro input: {pro_message}\")\n",
    "    logging.info(f\"Argument for: {arguments_for.argument}\")\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Con input: {con_message}\")\n",
    "    logging.info(f\"Argument against: {arguments_against.argument}\")\n",
    "    logging.info(\"===\")\n",
    "    logging.info(f\"Judge input: {judge_message}\")\n",
    "    logging.info(f\"Reasoning: {decision.reasoning}\")\n",
    "    logging.info(f\"Decision: {decision.decision}\")\n",
    "    logging.info(\"===\")\n",
    "\n",
    "    # Structured logs\n",
    "    if logger:\n",
    "        logger.log(\"property_details\", {\n",
    "            \"name\": dict_property_info['name'],\n",
    "            \"type\": dict_property_info['type'],\n",
    "            \"price\": dict_property_info['price'],\n",
    "            \"rent\": dict_property_info['rent'],\n",
    "            \"color\": dict_property_info.get('color', None)\n",
    "        })\n",
    "        logger.log(\"player_stats\", {\n",
    "            \"cash\": self.get_state()['cash'],\n",
    "            \"owned_roads_count\": len(self.get_state()['owned_roads']),\n",
    "            \"owned_stations_count\": len(self.get_state()['owned_stations']),\n",
    "            \"owned_utilities_count\": len(self.get_state()['owned_utilities']),\n",
    "            \"player_name\": self.get_state()['name']\n",
    "        })\n",
    "        logger.log(\"pro_argument_prompt\", pro_message)\n",
    "        logger.log(\"pro_argument_response\", arguments_for)\n",
    "        logger.log(\"con_argument_prompt\", con_message)\n",
    "        logger.log(\"con_argument_response\", arguments_against)\n",
    "        logger.log(\"judge_prompt\", judge_message)\n",
    "        logger.log(\"judge_response\", decision)\n",
    "\n",
    "    cached_decisions = add_to_vectorstore(\n",
    "        case_id=f\"{dict_property_info['name']}_{self.get_state()['name']}\",\n",
    "        context=f\"Property Details:\\n{property_details}\\nPlayer Stats:\\n{player_stats}\",\n",
    "        arguments=f\"For: {arguments_for.argument}\\nAgainst: {arguments_against.argument}\",\n",
    "        decision=f\"Decision: {\"Buy\" if decision.decision else \"Don't buy\"}\\nReasoning: {decision.reasoning}\",\n",
    "        vectorstore=self._vec,\n",
    "        CACHED_DECISIONS=self._cached_decisions,\n",
    "        reflection=reflect_before_vectorstore,\n",
    "        logger=logger\n",
    "    )\n",
    "    self._cached_decisions = cached_decisions\n",
    "    \n",
    "\n",
    "    # Return Decision\n",
    "    return \"buy\" if decision.decision else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_method(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "\n",
    "        result = func(self, *args, **kwargs)\n",
    "        logging.info(\"===\")\n",
    "        logging.info(f\"Calling {func.__name__} with args: {args}, kwargs: {kwargs}\")\n",
    "        logging.info(f\"{func.__name__} returned: {result}\")\n",
    "        logging.info(\"===\")\n",
    "\n",
    "        log_path = os.getenv(\"LOGGER_PATH\")\n",
    "        if log_path:\n",
    "            logger = StructuredLogger(log_path)\n",
    "            logger.log(\"default_decision\", {\n",
    "                \"args\": args,\n",
    "                \"kwargs\": kwargs,\n",
    "                \"result\": result\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class LoggedPlayer(Player):\n",
    "    @log_method\n",
    "    def buy_or_bid(self, *args, **kwargs):\n",
    "        return super().buy_or_bid(*args, **kwargs)\n",
    "\n",
    "def modify_buy_or_bid(buy) -> str:\n",
    "    return custom_buy\n",
    "\n",
    "class CustomPlayer(Player):\n",
    "    buy_or_bid = modify_buy_or_bid(Player.buy_or_bid)\n",
    "    # Will be overwritten by real vectorstore in init_game function\n",
    "    _vec = None\n",
    "    _cached_decisions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_game(vec: FAISS) -> dict:\n",
    "    \"\"\"\n",
    "    Initializes a game with two players and sets up the bank, board, roads, properties, \n",
    "    and community chest cards.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the following:\n",
    "            - \"bank\": Game's bank object.\n",
    "            - \"board\": Main game board.\n",
    "            - \"roads\": List of road objects.\n",
    "            - \"properties\": List of property objects.\n",
    "            - \"community_chest_cards\": Dictionary of community chest cards.\n",
    "            - \"players\": List of two Player objects, with Player 1 first.\n",
    "    \"\"\"\n",
    "    \n",
    "    bank = get_bank()\n",
    "    board = get_board()\n",
    "    roads = get_roads()\n",
    "    properties = get_properties()\n",
    "    community_chest_cards = get_community_chest_cards()\n",
    "    community_cards_deck = list(community_chest_cards.keys())\n",
    "\n",
    "    # Note how we have one of our players vs. a default player that just buys \n",
    "    # whenever cash is available. We can change this later\n",
    "    player1 = CustomPlayer('Alice', 1, bank, board, roads, properties, community_cards_deck)\n",
    "    player1._vec = vec\n",
    "    player2 = LoggedPlayer('Bob', 2, bank, board, roads, properties, community_cards_deck)\n",
    "    \n",
    "    player1.meet_other_players([player1, player2])\n",
    "    player2.meet_other_players([player1, player2])\n",
    "    \n",
    "    return {\n",
    "        \"bank\": bank,\n",
    "        \"board\": board,\n",
    "        \"roads\": roads,\n",
    "        \"properties\": properties,\n",
    "        \"community_chest_cards\": community_chest_cards,\n",
    "        \"players\": [player1, player2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner(players):\n",
    "    \"\"\"\n",
    "    Determine the winner among players. \n",
    "    \n",
    "    If exactly one player has lost, the other is the winner. \n",
    "    If neither has lost by the time we stop, pick the one with the \n",
    "    greatest net worth (cash + mortgageable_amount) as the winner.\n",
    "    Returns:\n",
    "        winner (Player)\n",
    "    \"\"\"\n",
    "    active_players = [p for p in players if not p.has_lost()]\n",
    "\n",
    "    if len(active_players) == 1:\n",
    "        # Exactly one survivor\n",
    "        return active_players[0]\n",
    "    else:\n",
    "        # More than one still in => compare net worth\n",
    "        # If there's a tie in net worth, we return None\n",
    "        top_player = None\n",
    "        top_net_worth = -1\n",
    "        \n",
    "        for p in active_players:\n",
    "            st = p.get_state()\n",
    "            net_worth = st[\"cash\"] + st[\"mortgageable_amount\"]\n",
    "            if net_worth > top_net_worth:\n",
    "                top_player = p\n",
    "                top_net_worth = net_worth\n",
    "            elif net_worth == top_net_worth:\n",
    "                # tie\n",
    "                top_player = None\n",
    "        \n",
    "        return top_player\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def players_state(players) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to get a logstring showing all players' states.\n",
    "    \"\"\"\n",
    "\n",
    "    state_obj = []\n",
    "    for player in players:\n",
    "        state_obj += [player.get_state()]\n",
    "    \n",
    "    return json.dumps(state_obj, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    open_ai_key: str,\n",
    "    raw_log_filepath: str,\n",
    "    win_rate_filepath: str,\n",
    "    max_steps_per_game: int = 10,\n",
    "    num_games: int = 10,\n",
    "    reflect_before_vectorstore: bool = False,\n",
    "    primary_model: str = \"gpt-4o-mini\",\n",
    "    primary_model_params: dict = {},\n",
    "    secondary_model: str = \"gpt-4o\",\n",
    "    secondary_model_params: dict = {},\n",
    "    random_seed: int = 42\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run an experiment with the given parameters, ensuring ALL data are saved.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    open_ai_key : str\n",
    "        The OpenAI API key.\n",
    "    raw_log_filepath : str\n",
    "        Base filepath to save outputs from all LLM completions and vectorstore \n",
    "        search results for each game. We'll append `_game{i}_timestamp.log`.\n",
    "    win_rate_filepath : str\n",
    "        Base filepath to save CSV of game outcomes (two columns: \n",
    "        'raw_log_filepath' and 'custom_agent_won'). We'll append `_timestamp.csv`.\n",
    "    max_steps_per_game : int, optional\n",
    "        The maximum number of steps per game.\n",
    "    num_games : int, optional\n",
    "        The number of games to play to get the average win rate.\n",
    "    reflect_before_vectorstore : bool, optional\n",
    "        Whether to reflect and summarize data before adding past context to \n",
    "        vectorstore.\n",
    "    primary_model : str, optional\n",
    "        Name of the primary fast LLM to use (for lawyer chains).\n",
    "    primary_model_params : dict, optional\n",
    "        Key-value pairs for the primary LLM (e.g. {\"temperature\": 0.7}).\n",
    "    secondary_model : str, optional\n",
    "        Name of the secondary slow LLM to use (for judge chains).\n",
    "    secondary_model_params : dict, optional\n",
    "        Key-value pairs for the secondary LLM (e.g. {\"temperature\": 0.0}).\n",
    "    \"\"\"\n",
    "\n",
    "    # Export model settings to environment variables\n",
    "    os.environ[\"OPENAI_API_KEY\"] = open_ai_key \n",
    "    os.environ[\"PRIMARY_MODEL_NAME\"] = primary_model\n",
    "    os.environ[\"SECONDARY_MODEL_NAME\"] = secondary_model\n",
    "    os.environ[\"REFLECT_BEFORE_VECTORSTORE\"] = str(reflect_before_vectorstore)\n",
    "\n",
    "    if primary_model_params:\n",
    "        os.environ[\"PRIMARY_MODEL_PARAMS\"] = json.dumps(primary_model_params)\n",
    "    if secondary_model_params:\n",
    "        os.environ[\"SECONDARY_MODEL_PARAMS\"] = json.dumps(secondary_model_params)\n",
    "\n",
    "    # Prepare path for CSV that tracks win/loss for each game\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    folder = f\"logs/fastslow/{\"reflect\" if reflect_before_vectorstore else \"noreflect\"}/{random_seed}/{timestamp_str}\"\n",
    "    final_win_rate_csv = f\"{folder}/{win_rate_filepath}.csv\"\n",
    "\n",
    "    # Ensure the directory exists for the CSV\n",
    "    os.makedirs(os.path.dirname(final_win_rate_csv), exist_ok=True)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Run multiple games\n",
    "    # -------------------------------------------------------------------------\n",
    "    with open(final_win_rate_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        writer.writerow([\"raw_log_filepath\", \"custom_agent_won\"])\n",
    "\n",
    "        for game_index in range(num_games):\n",
    "            print(f\"\\nStarting game {game_index}\")\n",
    "\n",
    "            # Archive and reset the vectorstore for each game\n",
    "            vec = init_vectorstore(timestamp_str, game_index)\n",
    "\n",
    "            # We'll log everything into a single .log file for this game\n",
    "            game_log_file = f\"{folder}/{raw_log_filepath}_game{game_index}.log\"\n",
    "            game_tsv_file = f\"{folder}/{raw_log_filepath}_game{game_index}.tsv\"\n",
    "            os.makedirs(os.path.dirname(game_log_file), exist_ok=True)\n",
    "            os.makedirs(os.path.dirname(game_tsv_file), exist_ok=True)\n",
    "\n",
    "            os.environ[\"LOGGER_PATH\"] = game_tsv_file\n",
    "            logger = StructuredLogger(game_tsv_file)\n",
    "            \n",
    "            logging.basicConfig(\n",
    "                filename=game_log_file, level=logging.INFO, force=True,\n",
    "                format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "            )\n",
    "            config = {\n",
    "                \"max_steps_per_game\": max_steps_per_game,\n",
    "                \"num_games\": num_games,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"primary_model\": primary_model,\n",
    "                \"primary_model_params\": primary_model_params,\n",
    "                \"secondary_model\": secondary_model,\n",
    "                \"secondary_model_params\": secondary_model_params,\n",
    "            }\n",
    "            logging.info(f\"Starting game {game_index} with config: {config}\")\n",
    "            logger.log(\"game_init\", config)\n",
    "            \n",
    "            game_data = initialize_game(vec)\n",
    "            players = game_data[\"players\"]\n",
    "\n",
    "            # Run up to max_steps_per_game\n",
    "            step = 0\n",
    "            while step < max_steps_per_game:\n",
    "                # Logging progress\n",
    "                print(step, end=\", \")\n",
    "                if (step + 1) % 30 == 0:\n",
    "                    print(\"\")\n",
    "                logging.info(\"===\")\n",
    "                logging.info(f\"Step {step}\")\n",
    "                logging.info(\"===\")\n",
    "                logger.log(\"step_num\", step)\n",
    "                logger.log(\"player_summary\", players_state(players))\n",
    "                \n",
    "                # Check if the game already ended\n",
    "                if any(p.has_lost() for p in players):\n",
    "                    break\n",
    "\n",
    "                for p in players:\n",
    "                    if not p.has_lost():\n",
    "                        p.play()\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            # Determine winner\n",
    "            winner = get_winner(players)\n",
    "\n",
    "            # Check if the winner is our custom agent (player1 in this setup)\n",
    "            custom_agent = players[0]\n",
    "            custom_agent_won = (winner == custom_agent)\n",
    "\n",
    "            # Write to CSV\n",
    "            writer.writerow([game_log_file, str(custom_agent_won)])\n",
    "\n",
    "    print(f\"\\nAll {num_games} games complete. Results saved to: {final_win_rate_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting game 0\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n",
      "Starting game 1\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n",
      "All 2 games complete. Results saved to: logs/courtroom/20250226_181706/courtroom_win_rate.csv\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    open_ai_key=openai_key,\n",
    "    raw_log_filepath=\"courtroom_raw\",\n",
    "    win_rate_filepath=\"courtroom_win_rate\",\n",
    "    max_steps_per_game=200,\n",
    "    num_games=20,\n",
    "    reflect_before_vectorstore=True,\n",
    "    primary_model=\"gpt-4o-mini\",\n",
    "    primary_model_params={\"temperature\": 1.0, \"max_tokens\": 2048},\n",
    "    secondary_model=\"gpt-4o\",\n",
    "    secondary_model_params={\"temperature\": 1.0, \"max_tokens\": 2048},\n",
    "    random_seed = 42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
