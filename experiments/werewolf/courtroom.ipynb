{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werewolf Simulator\n",
    "The following runs a simulation of the game Werewolf with multiple agents, it is built on top of and uses the Agentscope library, documentation can be found here https://doc.agentscope.io/, and the open source code that we extend on is here https://github.com/modelscope/agentscope/tree/main.\n",
    "### Rules of Werewolf\n",
    "- There are 4 roles, the Werewolves, Villagers, Witch, and Seer (Witch and Seer are on the Villager team)\n",
    "- Each night:\n",
    "    - The Werewolves discuss and vote on a player to eliminate\n",
    "    - The Witch is told what player the wolves voted to eliminate, and is given the choice to use their potion of healing to reserruct the eliminated player, or use their poison to eliminate another player. Note that each power can only be used once in a game\n",
    "    - The seer can pick any other player and find out what their role is (one player per night)\n",
    "- After the events of the night, all surviving players discuss amongst themselves and vote on a player to eliminate\n",
    "- Werewolves win if their numbers equal or exceed Villagers.\n",
    "- Villagers win if all Werewolves are eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentscope==0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: faiss-cpu==1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: black in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (25.1.0)\n",
      "Requirement already satisfied: docstring-parser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (0.16)\n",
      "Requirement already satisfied: pydantic in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: loguru==0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: inputimeout in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (1.0.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: Flask==3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: Flask-Cors==4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: Flask-SocketIO==5.3.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (5.3.6)\n",
      "Requirement already satisfied: flask-sqlalchemy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: flake8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: psutil in /Users/Evan/Library/Python/3.12/lib/python/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: openai>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (1.63.0)\n",
      "Requirement already satisfied: dashscope>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from agentscope==0.1.1->-r requirements.txt (line 1)) (1.22.1)\n",
      "Requirement already satisfied: packaging in /Users/Evan/Library/Python/3.12/lib/python/site-packages (from faiss-cpu==1.9.0->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: python-socketio>=5.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask-SocketIO==5.3.6->agentscope==0.1.1->-r requirements.txt (line 1)) (5.12.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (3.11.12)\n",
      "Requirement already satisfied: websocket-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic->agentscope==0.1.1->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic->agentscope==0.1.1->-r requirements.txt (line 1)) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from black->agentscope==0.1.1->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from black->agentscope==0.1.1->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/Evan/Library/Python/3.12/lib/python/site-packages (from black->agentscope==0.1.1->-r requirements.txt (line 1)) (4.3.6)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from flake8->agentscope==0.1.1->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.13.0,>=2.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from flake8->agentscope==0.1.1->-r requirements.txt (line 1)) (2.12.1)\n",
      "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from flake8->agentscope==0.1.1->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from flask-sqlalchemy->agentscope==0.1.1->-r requirements.txt (line 1)) (2.0.38)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->agentscope==0.1.1->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->agentscope==0.1.1->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->agentscope==0.1.1->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->agentscope==0.1.1->-r requirements.txt (line 1)) (2024.12.14)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->agentscope==0.1.1->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3.0->agentscope==0.1.1->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Jinja2>=3.1.2->Flask==3.0.0->agentscope==0.1.1->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: bidict>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-socketio>=5.0.2->Flask-SocketIO==5.3.6->agentscope==0.1.1->-r requirements.txt (line 1)) (0.23.1)\n",
      "Requirement already satisfied: python-engineio>=4.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-socketio>=5.0.2->Flask-SocketIO==5.3.6->agentscope==0.1.1->-r requirements.txt (line 1)) (4.11.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->dashscope>=1.19.0->agentscope==0.1.1->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-engineio>=4.11.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.6->agentscope==0.1.1->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: wsproto in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.0.2->Flask-SocketIO==5.3.6->agentscope==0.1.1->-r requirements.txt (line 1)) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Optional, Union, Sequence, Any, List\n",
    "from functools import partial\n",
    "import openai  \n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import random \n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import sys\n",
    "import time\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "\n",
    "from agentscope.parsers.json_object_parser import MarkdownJsonDictParser\n",
    "from agentscope.parsers import ParserBase\n",
    "from agentscope.message import Msg\n",
    "from agentscope.msghub import msghub\n",
    "from agentscope.agents import AgentBase\n",
    "from agentscope.memory.temporary_memory import TemporaryMemory\n",
    "from agentscope.pipelines.functional import sequentialpipeline\n",
    "import agentscope\n",
    "\n",
    "from utils.werewolf_utils import (\n",
    "    extract_name_and_id,\n",
    "    n2s,\n",
    "    set_parsers,\n",
    "    generate_model_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log configuration\n",
    "LOG_LEVEL = logging.INFO\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# Initial logging setup\n",
    "logging.basicConfig(\n",
    "    filename=None,\n",
    "    level=LOG_LEVEL,\n",
    "    format=LOG_FORMAT,\n",
    "    datefmt=DATE_FORMAT\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def change_log_file(new_filename: str):\n",
    "    \"\"\"\n",
    "    Updates the logger handler to point to a different log file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all old handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "        handler.close()\n",
    "\n",
    "    # Create a new file handler\n",
    "    new_handler = logging.FileHandler(new_filename)\n",
    "    new_handler.setLevel(LOG_LEVEL)  # Reset level\n",
    "    new_handler.setFormatter(logging.Formatter(LOG_FORMAT, datefmt=DATE_FORMAT))  # Reset formatter\n",
    "\n",
    "    # Add new handler to logger\n",
    "    logger.addHandler(new_handler)\n",
    "\n",
    "def log_params(log_filepath: str, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Writes all parameters passed to the function into a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        log_filepath (str): Path where the JSON file will be written.\n",
    "        **kwargs: Any number of keyword arguments representing parameter names and values.\n",
    "    \"\"\"\n",
    "    with open(log_filepath, \"w\") as file:\n",
    "        json.dump(kwargs, file, separators=(\",\", \":\"))  # Compact JSON\n",
    "        file.write(\"\\n\")  # Ensures a newline at the end\n",
    "\n",
    "    print(f\"Parameters written to {log_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store Implementations\n",
    "Vector store classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectiveVectorstoreMemory:\n",
    "    \"\"\"Reflective Vectorstore-based memory using FAISS and OpenAI embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model: str = \"text-embedding-ada-002\"):\n",
    "        \"\"\"\n",
    "        Initialize the vectorstore with FAISS and OpenAI embeddings.\n",
    "        \n",
    "        Args:\n",
    "            embedding_model (str): The OpenAI embedding model to use.\n",
    "        \"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "        # Vector Store\n",
    "        self.index = faiss.IndexFlatL2(1536)  # 1536 is the dimensionality of 'text-embedding-ada-002'\n",
    "        self.messages = []  # To store actual messages (content)\n",
    "        self.summaries = []  # To store summaries\n",
    "\n",
    "    def _get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate an embedding for the given text using OpenAI.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to embed.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: The embedding vector as a NumPy array.\n",
    "        \"\"\"\n",
    "        client = openai.OpenAI()\n",
    "\n",
    "        response = retry_with_fallback(lambda: client.embeddings.create(\n",
    "            input=text,\n",
    "            model=self.embedding_model\n",
    "        ))\n",
    "        \n",
    "        return np.array(response.data[0].embedding, dtype=\"float32\")\n",
    "\n",
    "    def add_message(self, message: Union[Msg, Sequence[Msg]]):\n",
    "        \"\"\"Add a message to the FAISS index.\"\"\"\n",
    "        if not isinstance(message, list):\n",
    "            message = [message]\n",
    "        for msg in message:\n",
    "            self.messages.append(msg.name + \": \" + msg.content)\n",
    "        \n",
    "    def summarize_cycle(self, survivors: list, secondary_model: str, cycle_type: str = \"day\"):\n",
    "        \"\"\"\n",
    "        Generate a summary of the conversation after a day/night cycle,\n",
    "        and add it to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            survivors (list): List of current alive players.\n",
    "            secondary_model (str): Name of secondary model.\n",
    "            cycle_type (str): The type of cycle (\"day\" or \"night\").\n",
    "        \"\"\"\n",
    "        client = openai.OpenAI()\n",
    "        \n",
    "        # Combine all messages since the last summary\n",
    "        history = \"\\n\".join(self.messages)\n",
    "\n",
    "        # Use retry_with_fallback with a lambda function\n",
    "        secondary_model_response = retry_with_fallback(\n",
    "            lambda: client.chat.completions.create(\n",
    "                model=secondary_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\\n\".join([ \n",
    "                        f\"You are a strategic decision-maker reviewing past decisions in Werewolf.\",\n",
    "                        f\"Survivors: {\", \".join([survivor.name for survivor in survivors])}\",\n",
    "                        f\"Summarize the decisions and reflect on the most important implications for future strategic decisions.\"\n",
    "                    ])},\n",
    "                    {\"role\": \"user\", \"content\": history},\n",
    "                ],\n",
    "                max_tokens=4096\n",
    "            )\n",
    "        )\n",
    "\n",
    "        summary = secondary_model_response.choices[0].message.content\n",
    "\n",
    "        # Embed the summary and add it to the vector store\n",
    "        embedding = self._get_embedding(summary)\n",
    "        self.index.add(np.array([embedding]))\n",
    "        self.summaries.append(summary)\n",
    "\n",
    "        # Clear messages for the next cycle\n",
    "        self.messages.clear()\n",
    "\n",
    "    def get_relevant_summaries_context(self, query: str, top_k: int = 1) -> str:\n",
    "        \"\"\"Retrieve the top-k most relevant summaries.\n",
    "        \n",
    "        Args:\n",
    "            query (str): query to find similar summaries to.\n",
    "            top_k (int): number of relevant summaries to retrieve.\n",
    "        \"\"\"\n",
    "        if len(self.summaries) > 0:\n",
    "            query_embedding = self._get_embedding(query)\n",
    "            distances, indices = self.index.search(np.array([query_embedding]), top_k)\n",
    "            results = [\n",
    "                self.summaries[idx] for idx in indices[0] if idx < len(self.summaries)\n",
    "            ]\n",
    "            return \"\\n\".join(results)\n",
    "        return \"\"\n",
    "    \n",
    "    def save_context(self, game_num: int, player_role: str):\n",
    "        \"\"\"\n",
    "        Save self.messages to a log file in the format:\n",
    "        vectorstore/[timestamp]/[game_num]/[player_role].log\n",
    "\n",
    "        Args:\n",
    "            game_num (int): The game index.\n",
    "            player_role (str): The role of the player.\n",
    "        \"\"\"\n",
    "        # Get the timestamp in the required format\n",
    "        est_now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
    "        iso_timestamp = est_now.isoformat(timespec='seconds').replace(\":\", \"-\")\n",
    "\n",
    "        # Construct the directory path\n",
    "        dir_path = os.path.join(\"vectorstore\", iso_timestamp, str(game_num))\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        # Construct the file path\n",
    "        file_path = os.path.join(dir_path, f\"{player_role}.log\")\n",
    "\n",
    "        # Save messages to the log file\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(\"\\n===\\n\".join(self.summaries))\n",
    "\n",
    "        print(f\"Messages saved to {file_path}\")\n",
    "\n",
    "class VectorstoreMemory:\n",
    "    \"\"\"Vectorstore-based memory using FAISS and OpenAI embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model: str = \"text-embedding-ada-002\"):\n",
    "        \"\"\"\n",
    "        Initialize the vectorstore with FAISS and OpenAI embeddings.\n",
    "        \n",
    "        Args:\n",
    "            embedding_model (str): The OpenAI embedding model to use.\n",
    "        \"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "        # Vector Store\n",
    "        self.index = faiss.IndexFlatL2(1536)  # 1536 is the dimensionality of 'text-embedding-ada-002'\n",
    "        self.messages = []  # To store actual messages (content)\n",
    "\n",
    "    def _get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate an embedding for the given text using OpenAI.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to embed.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: The embedding vector as a NumPy array.\n",
    "        \"\"\"\n",
    "        client = openai.OpenAI()\n",
    "        response = retry_with_fallback(lambda: client.embeddings.create(\n",
    "            input=text,\n",
    "            model=self.embedding_model\n",
    "        ))\n",
    "        return np.array(response.data[0].embedding, dtype=\"float32\")\n",
    "\n",
    "    def add_message(self, message: Union[Msg, Sequence[Msg]]):\n",
    "        \"\"\"Add a message to the FAISS index.\"\"\"\n",
    "        if not isinstance(message, list):\n",
    "            message = [message]\n",
    "        # add embedding of message to vector store\n",
    "        embeddings = [self._get_embedding(msg.name + \": \" + msg.content) for msg in message]\n",
    "        self.index.add(np.array(embeddings)) \n",
    "        self.messages.extend(message)\n",
    "\n",
    "    def get_relevant_messages(self, query: str, top_k: int = 10) -> list:\n",
    "        \"\"\"Retrieve the top-k most relevant messages.\"\"\"\n",
    "        if not self.messages:\n",
    "            return []\n",
    "        query_embedding = self._get_embedding(query)\n",
    "        distances, indices = self.index.search(np.array([query_embedding]), top_k)\n",
    "\n",
    "        results = [\n",
    "            self.messages[idx] for idx in indices[0] if idx < len(self.messages)\n",
    "        ]\n",
    "        return results\n",
    "\n",
    "    def save_context(self, game_num: int, player_role: str):\n",
    "        \"\"\"\n",
    "        Save self.messages to a log file in the format:\n",
    "        vectorstore/[timestamp]/[game_num]/[player_role].log\n",
    "\n",
    "        Args:\n",
    "            game_num (int): The game index.\n",
    "            player_role (str): The role of the player.\n",
    "        \"\"\"\n",
    "        # Get the timestamp in the required format\n",
    "        est_now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
    "        iso_timestamp = est_now.isoformat(timespec='seconds').replace(\":\", \"-\")\n",
    "\n",
    "        # Construct the directory path\n",
    "        dir_path = os.path.join(\"vectorstore\", iso_timestamp, str(game_num))\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        # Construct the file path\n",
    "        file_path = os.path.join(dir_path, f\"{player_role}.log\")\n",
    "\n",
    "        # Save messages to the log file\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(\"\\n===\\n\".join(self.summaries))\n",
    "\n",
    "        print(f\"Messages saved to {file_path}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agents (edit here)\n",
    "You can define custom Agents by inheriting from the AgentBase class like shown here.\n",
    "\n",
    "Below is a copy of the DictDialogAgent that generates responses in a dict format that is compatible with our simulator. More documentation on AgentScope agents can be found here https://doc.agentscope.io/build_tutorial/builtin_agent.html, existing agent implementations can be found here https://github.com/modelscope/agentscope/tree/main/src/agentscope/agents.\n",
    "\n",
    "For our case, modifying the agent class is, in conjunction with the parsers we pass in (more details in next cell), play a critical role in defining our agent behavior. We can edit this section by either defining a brand new agent type we want to explore, or modifying the current one. The primary (and mostly only) source of focus should be the reply the function in the agent class as that controls what an agent uses to generate a response, particular when we are working with different architectures, eg. how we use memory, single vs multi agent, we make those edits here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lawyer(AgentBase):\n",
    "    \"\"\"An agent specializing in constructing LLM-based arguments to eliminate a specific target in the Werewolf game.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        sys_prompt: str,\n",
    "        model_config_name: str,\n",
    "        parser,\n",
    "        context_messages: list,\n",
    "        memory\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Lawyer agent.\n",
    "\n",
    "        Args:\n",
    "            name (str): Name of the Lawyer agent.\n",
    "            sys_prompt (str): System prompt containing role instructions and context.\n",
    "            model_config_name (str): Identifier for the model configuration that determines the LLM to be used.\n",
    "            parser (ParserBase): Object responsible for formatting LLM outputs and extracting structured responses.\n",
    "            context_messages (list): A list of prior messages providing context for the lawyer’s argumentation.\n",
    "            memory: Memory management component used to store conversation history or additional data.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            sys_prompt=sys_prompt,\n",
    "            model_config_name=model_config_name,\n",
    "        )\n",
    "        self.parser = parser\n",
    "        self.context_messages = context_messages\n",
    "        self.memory = memory\n",
    "        self.model_config_name = model_config_name\n",
    "\n",
    "    def argue(self, available_targets: list) -> dict:\n",
    "        \"\"\"\n",
    "        Generate a rationale for eliminating a particular player in the Werewolf game.\n",
    "\n",
    "        Args:\n",
    "            game_state (dict): The current state of the game (e.g., who is alive, who is dead).\n",
    "            available_targets (list): List of potential targets that can be selected for elimination.\n",
    "\n",
    "        Returns:\n",
    "            dict:\n",
    "                A dictionary containing:\n",
    "                  - \"target\" (str): The chosen player to eliminate.\n",
    "                  - \"argument\" (str): The Lawyer’s supporting reasoning.\n",
    "        \"\"\"\n",
    "        if not available_targets:\n",
    "            return {\"target\": None, \"argument\": \"No valid targets available.\"}\n",
    "        \n",
    "        target = random.choice(available_targets) # Select random a target to argue for\n",
    "\n",
    "        # Construct prompt for argument generation\n",
    "        lawyer_prompt_with_target = Prompts.lawyer_prompt.format(target)\n",
    "\n",
    "        # Prepare the prompt for the model\n",
    "        formatted_prompt = self.model.format(\n",
    "            Msg(\"system\", self.sys_prompt, role=\"system\"),\n",
    "            Msg(\"system\", lawyer_prompt_with_target, role=\"system\"),\n",
    "            self.context_messages,\n",
    "            Msg(\"system\", self.parser.format_instruction, \"system\"),\n",
    "        )\n",
    "\n",
    "        # Call the LLM to generate an argument\n",
    "        raw_response = retry_with_fallback(\n",
    "            lambda: generate_model_response(self.model_config_name, formatted_prompt)\n",
    "        )\n",
    "\n",
    "        parsed_response = self.parser.parse(raw_response).parsed\n",
    "\n",
    "        return {\n",
    "            \"target\": target,\n",
    "            \"argument\": parsed_response\n",
    "        }\n",
    "\n",
    "class Judge(AgentBase):\n",
    "    \"\"\"An agent that evaluates competing arguments and selects who should be eliminated in the Werewolf game.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        sys_prompt: str,\n",
    "        model_config_name: str,\n",
    "        parser,\n",
    "        context_messages: list,\n",
    "        memory\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Judge agent.\n",
    "\n",
    "        Args:\n",
    "            name (str): Name of the Judge agent.\n",
    "            sys_prompt (str): System prompt containing role instructions and context.\n",
    "            model_config_name (str): Identifier for the model configuration that determines the LLM to be used.\n",
    "            parser (ParserBase): Object responsible for formatting LLM outputs and extracting structured responses.\n",
    "            context_messages (list): List of prior messages providing context for the Judge’s decision-making.\n",
    "            memory: Memory component used to store and retrieve conversation or historical data.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            sys_prompt=sys_prompt,\n",
    "            model_config_name=model_config_name,\n",
    "        )\n",
    "        self.parser = parser\n",
    "        self.context_messages = context_messages\n",
    "        self.memory = memory\n",
    "        self.model_config_name = model_config_name\n",
    "\n",
    "    def decide(self, game_state: dict, argument_1: dict, argument_2: dict):\n",
    "        \"\"\"\n",
    "        Evaluate two lawyers' arguments and choose a target for elimination.\n",
    "\n",
    "        Args:\n",
    "            game_state (dict): The current state of the Werewolf game (e.g., which players are alive or dead).\n",
    "            argument_1 (dict):\n",
    "                First lawyer’s argument dictionary with:\n",
    "                  - \"target\" (str): Proposed player to eliminate.\n",
    "                  - \"argument\" (str): Reasoning for that choice.\n",
    "            argument_2 (dict): Second lawyer’s argument dictionary with the same keys as argument_1.\n",
    "\n",
    "        Returns:\n",
    "            The raw response from the model, containing the Judge’s final decision.\n",
    "        \"\"\"\n",
    "        target_1 = argument_1[\"target\"]\n",
    "        argument_1 = argument_1[\"argument\"]\n",
    "        \n",
    "        target_2 = argument_2[\"target\"]\n",
    "        argument_2 = argument_2[\"argument\"]\n",
    "\n",
    "        # Construct formatted judge prompt\n",
    "        formatted_judge_prompt = Prompts.judge_prompt.format(game_state[\"survivors\"], game_state[\"dead\"], game_state[\"werewolves\"], target_1, argument_1, target_2, argument_2)\n",
    "\n",
    "        # Prepare the prompt for the model\n",
    "        formatted_prompt = self.model.format(\n",
    "            Msg(\"system\", self.sys_prompt, role=\"system\"),\n",
    "            Msg(\"system\", formatted_judge_prompt, role=\"system\"),\n",
    "            Msg(\"system\", self.parser.format_instruction, \"system\"),\n",
    "        )\n",
    "\n",
    "        raw_response = retry_with_fallback(\n",
    "            lambda: generate_model_response(self.model_config_name, formatted_prompt)\n",
    "        )\n",
    "\n",
    "        return raw_response\n",
    "\n",
    "class WerewolfAgent(AgentBase):\n",
    "    \"\"\"\n",
    "    Represents a \"werewolf\" in the game, producing responses in dict form.\n",
    "\n",
    "    Optionally uses reflective memory before retrieving context from a FAISS vectorstore.\n",
    "    Contains parsing capabilities to ensure structured outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        sys_prompt: str,\n",
    "        model_config_name: str,\n",
    "        reflect_before_vectorstore: bool,\n",
    "        similarity_top_k: int = 1,\n",
    "        openai_api_key: str = \"\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the WerewolfAgent.\n",
    "\n",
    "        Args:\n",
    "            name (str): Name of the agent.\n",
    "            sys_prompt (str): System prompt providing role context and instructions.\n",
    "            model_config_name (str): Name of the model configuration, indicating which LLM will be used.\n",
    "            reflect_before_vectorstore (bool): Whether to summarize or reflect on memory before retrieving vectorstore data.\n",
    "            similarity_top_k (int, optional): The number of most similar messages/summaries to retrieve from the vectorstore.\n",
    "            openai_api_key (str, optional): API key for OpenAI integration.\n",
    "            model: The underlying LLM for generating responses.\n",
    "            parser (ParserBase): Parser responsible for structuring, filtering, and formatting model outputs.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            sys_prompt=sys_prompt,\n",
    "            model_config_name=model_config_name,\n",
    "        )\n",
    "\n",
    "        self.parser = None\n",
    "        self.reflect_before_vectorstore = reflect_before_vectorstore\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "        self.model_config_name = model_config_name\n",
    "\n",
    "        # Set OpenAI API key\n",
    "        openai.api_key = openai_api_key\n",
    "\n",
    "        # Initialize FAISS-based memory store\n",
    "        if reflect_before_vectorstore:\n",
    "            self.memory = ReflectiveVectorstoreMemory()\n",
    "        else:\n",
    "            self.memory = VectorstoreMemory()\n",
    "\n",
    "    def set_parser(self, parser: ParserBase) -> None:\n",
    "        \"\"\"\n",
    "        Set the parser for handling model outputs.\n",
    "\n",
    "        This parser governs how responses are formatted, parsed,\n",
    "        and stored (including any filtering of fields).\n",
    "        \"\"\"\n",
    "        self.parser = parser\n",
    "\n",
    "    def reply(self, x: Optional[Union[Msg, Sequence[Msg]]] = None) -> Msg:\n",
    "        \"\"\"\n",
    "        Generate a response based on input messages, optionally retrieving context from memory.\n",
    "\n",
    "        Args:\n",
    "            x (Optional[Union[Msg, Sequence[Msg]]], optional):\n",
    "                The input message(s) to process.\n",
    "\n",
    "        Returns:\n",
    "            Msg:\n",
    "                The assistant's structured output, including any metadata defined by the parser.\n",
    "        \"\"\" \n",
    "        query = Queries.werewolf_discussion_query\n",
    "\n",
    "        # Retrieve relevant messages from memory\n",
    "        if self.reflect_before_vectorstore:\n",
    "            summary_context = self.memory.get_relevant_summaries_context(query=query, top_k=self.similarity_top_k)\n",
    "            logger.info(f\"Relevant messages from vectorstore: {summary_context}\")\n",
    "\n",
    "            # Prepare prompt with context from retrieved summaries\n",
    "            prompt = self.model.format(\n",
    "                Msg(\"system\", self.sys_prompt, role=\"system\"),\n",
    "                Msg(name=\"system\", role=\"system\", content=f\"Summary of relevant past conversations: {summary_context}\"),\n",
    "                x,\n",
    "                Msg(\"system\", self.parser.format_instruction, \"system\"),\n",
    "            )\n",
    "        else:\n",
    "            relevant_messages = self.memory.get_relevant_messages(query=query, top_k=self.similarity_top_k)\n",
    "\n",
    "            logger.info(f\"Relevant messages from vectorstore: {convert_messages_to_string(relevant_messages)}\")\n",
    "\n",
    "            # Prepare prompt with retrieved messages similar to input message\n",
    "            prompt = self.model.format(\n",
    "                Msg(\"system\", self.sys_prompt, role=\"system\"),\n",
    "                relevant_messages and Msg(\"system\", f\"Relevant messages from memory: {relevant_messages}\", \"system\"),\n",
    "                x,\n",
    "                Msg(\"system\", self.parser.format_instruction, \"system\"),\n",
    "            )\n",
    "\n",
    "        # Call the LLM\n",
    "        raw_response = retry_with_fallback(lambda: generate_model_response(self.model_config_name, prompt))\n",
    "\n",
    "        self.speak(raw_response.text)\n",
    "\n",
    "        # Parse the raw response\n",
    "        parsed_response = self.parser.parse(raw_response).parsed\n",
    "\n",
    "        vectorstore_entry = Msg(\n",
    "            self.name,\n",
    "            content=json.dumps(parsed_response),\n",
    "            role=\"assistant\",\n",
    "        )\n",
    "\n",
    "        # Save the response to memory\n",
    "        self.memory.add_message(message=vectorstore_entry)\n",
    "\n",
    "        msg = Msg(\n",
    "            self.name,\n",
    "            content=self.parser.to_content(parsed_response),\n",
    "            role=\"assistant\",\n",
    "            metadata=self.parser.to_metadata(parsed_response),\n",
    "        )\n",
    "\n",
    "        return msg\n",
    "\n",
    "    def lawyer_judge_decision(self, game_state: dict, available_targets: list, x: Optional[Union[Msg, Sequence[Msg]]] = None) -> Msg:\n",
    "        \"\"\"\n",
    "        Make an elimination decision by invoking two Lawyers and one Judge.\n",
    "\n",
    "        Args:\n",
    "            game_state (dict): The current state of the Werewolf game (e.g., active players, werewolves).\n",
    "            x (Optional[Union[Msg, Sequence[Msg]]], optional): Optionally, messages to be recorded in memory before decision-making.\n",
    "\n",
    "        Returns:\n",
    "            Msg:\n",
    "                The final decision from the Judge as a structured message.\n",
    "        \"\"\"\n",
    "        query = Queries.werewolf_discussion_query \n",
    "\n",
    "        # Retrieve relevant messages from memory (summaries or direct messages)\n",
    "        if self.reflect_before_vectorstore:\n",
    "            summary_context = self.memory.get_relevant_summaries_context(query=query, top_k=self.similarity_top_k)\n",
    "            \n",
    "            relevant_messages = [Msg(name=\"system\", role=\"system\", content=f\"Summary of relevant past conversations: {summary_context}\")]\n",
    "            logger.info(f\"Relevant messages from vectorstore: {summary_context}\")\n",
    "        else:\n",
    "            assert isinstance(query, str), f\"Expected a string, but got {type(query)}\"\n",
    "            relevant_messages = self.memory.get_relevant_messages(query=query, top_k=self.similarity_top_k) or [x]\n",
    "\n",
    "            logger.info(f\"Relevant messages from vectorstore: {convert_messages_to_string(relevant_messages)}\")\n",
    "            \n",
    "        # Initialize the lawyers and judge\n",
    "        lawyer_1 = Lawyer(\n",
    "            f'{self.name} (Lawyer 1)',\n",
    "            self.sys_prompt,\n",
    "            self.model_config_name,\n",
    "            self.parser,\n",
    "            relevant_messages,              \n",
    "            self.memory\n",
    "        )\n",
    "\n",
    "        lawyer_2 = Lawyer(\n",
    "            f'{self.name} (Lawyer 2)',\n",
    "            self.sys_prompt,\n",
    "            self.model_config_name,\n",
    "            self.parser,\n",
    "            relevant_messages,\n",
    "            self.memory\n",
    "        )\n",
    "\n",
    "        judge = Judge(\n",
    "            f'{self.name} (Judge)',\n",
    "            self.sys_prompt,\n",
    "            self.model_config_name,\n",
    "            self.parser,\n",
    "            relevant_messages,\n",
    "            self.memory\n",
    "        )\n",
    "    \n",
    "        lawyer_1_argument = lawyer_1.argue(available_targets)\n",
    "        available_targets.remove(lawyer_1_argument[\"target\"])\n",
    "        lawyer_2_argument = lawyer_2.argue(available_targets)\n",
    "\n",
    "        raw_response = judge.decide(game_state, lawyer_1_argument, lawyer_2_argument)\n",
    "        logger.info(f\"Lawyer 1 argument: {lawyer_1_argument}\")\n",
    "        logger.info(f\"Lawyer 2 argument: {lawyer_2_argument}\")\n",
    "        logger.info(f\"Judge decision: {load_json_response(raw_response.text)}\")\n",
    "\n",
    "        self.speak(raw_response.text)\n",
    "\n",
    "        # Parse response\n",
    "        res = self.parser.parse(raw_response)\n",
    "\n",
    "        vectorstore_entry = Msg(\n",
    "            self.name,\n",
    "            content=\"\\n\".join([\n",
    "                f\"Argument 1: {lawyer_1_argument}\",\n",
    "                f\"Argument 2: {lawyer_2_argument}\",\n",
    "                f\"Decision: {res.parsed}\"\n",
    "            ]),\n",
    "            role=\"assistant\"\n",
    "        )\n",
    "\n",
    "        # Store final decision\n",
    "        self.memory.add_message(message=vectorstore_entry)\n",
    "\n",
    "        msg = Msg(\n",
    "            self.name,\n",
    "            content=self.parser.to_content(res.parsed),\n",
    "            role=\"assistant\",\n",
    "            metadata=self.parser.to_metadata(res.parsed),\n",
    "        )\n",
    "\n",
    "        return msg\n",
    "\n",
    "    def observe(self, x: Union[Msg, Sequence[Msg]], role: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Record incoming messages in memory without generating a reply.\n",
    "\n",
    "        Args:\n",
    "            x (Union[Msg, Sequence[Msg]]): The message(s) to be stored in memory for future context.\n",
    "            role (`str`, optional): Role of the observer\n",
    "        \"\"\"\n",
    "        if role == \"seer\" and x is not None:\n",
    "            self.memory.add_message(message=x)\n",
    "\n",
    "    def summarize_cycle(self, survivors: list, secondary_model: str, cycle_type: str = \"day\"):\n",
    "        \"\"\"\n",
    "        Produce a summary of key events at the end of a day or night cycle.\n",
    "\n",
    "        Args:\n",
    "            survivors: (list): List of current survivors.\n",
    "            secondary_model (str): Name of secondary model.\n",
    "            cycle_type (str, optional): The type of cycle being summarized, either \"day\" or \"night\".\n",
    "        \"\"\"\n",
    "        self.memory.summarize_cycle(survivors, secondary_model, cycle_type=cycle_type)\n",
    "\n",
    "    def save_context(self, game_num: int, player_role: str=\"werewolf\"):\n",
    "        \"\"\"\n",
    "        Save self.messages to a log file in the format:\n",
    "        vectorstore/[timestamp]/[game_num]/[player_role].log\n",
    "\n",
    "        Args:\n",
    "            game_num (int): The game index.\n",
    "            player_role (str): The role of the player.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.memory.save_context(game_num, player_role)\n",
    "\n",
    "class NormalAgent(AgentBase):\n",
    "    \"\"\"\n",
    "    A general-purpose agent that returns structured responses in JSON/dict format.\n",
    "\n",
    "    Integrates with a FAISS vectorstore for context retrieval.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        sys_prompt: str,\n",
    "        model_config_name: str,\n",
    "        reflect_before_vectorstore: bool,\n",
    "        similarity_top_k: int = 1,\n",
    "        openai_api_key: str = \"\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the NormalAgent.\n",
    "\n",
    "        Args:\n",
    "            name (str): Agent name.\n",
    "            sys_prompt (str): The system prompt containing the agent’s role instructions.\n",
    "            model_config_name (str): Indicates which model configuration the agent should use.\n",
    "            reflect_before_vectorstore (bool): Flag to determine if reflective memory is used before vectorstore retrieval.\n",
    "            similarity_top_k (int, optional): The number of top similar items from the vectorstore to include as context.\n",
    "            openai_api_key (str, optional): API key for integrating with OpenAI services.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            sys_prompt=sys_prompt,\n",
    "            model_config_name=model_config_name,\n",
    "        )\n",
    "\n",
    "        self.parser = None\n",
    "        openai.api_key = openai_api_key\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "        self.reflect_before_vectorstore = reflect_before_vectorstore\n",
    "        self.model_config_name = model_config_name\n",
    "        self.memory = VectorstoreMemory()\n",
    "\n",
    "    def set_parser(self, parser: ParserBase) -> None:\n",
    "        \"\"\"\n",
    "        Configure the parser that dictates how outputs are formatted, parsed, and stored.\n",
    "\n",
    "        By adjusting the parser, you can control the entire pipeline of formatting and extraction\n",
    "        for the model's responses.\n",
    "        \"\"\"\n",
    "        self.parser = parser\n",
    "\n",
    "    def reply(self, x: Optional[Union[Msg, Sequence[Msg]]] = None) -> Msg:\n",
    "        \"\"\"\n",
    "        Generate a response based on provided input messages, using stored context as needed.\n",
    "\n",
    "        Args: \n",
    "            x (Optional[Union[Msg, Sequence[Msg]]], optional): The incoming user or system messages.\n",
    "\n",
    "        Returns:\n",
    "            Msg:\n",
    "                A structured message including the assistant's content and any parsed metadata.\n",
    "        \"\"\"\n",
    "        query = Queries.non_werewolf_discussion_query\n",
    "\n",
    "        # Retrieve similar messages from memory\n",
    "        relevant_messages = self.memory.get_relevant_messages(query=query, top_k=self.similarity_top_k)\n",
    "        logger.info(f\"Relevant messages from vectorstore: {convert_messages_to_string(relevant_messages)}\")\n",
    "\n",
    "        # Prepare the prompt with relevant context\n",
    "        prompt = self.model.format(\n",
    "            Msg(\"system\", self.sys_prompt, role=\"system\"),\n",
    "            relevant_messages and Msg(\"system\", f\"Relevant messages from memory: {relevant_messages}\", \"system\"),\n",
    "            x,\n",
    "            Msg(\"system\", self.parser.format_instruction, \"system\"),\n",
    "        )\n",
    "\n",
    "        # Call the LLM\n",
    "        raw_response = retry_with_fallback(\n",
    "            lambda: generate_model_response(self.model_config_name, prompt)\n",
    "        )\n",
    "\n",
    "        self.speak(raw_response.text)\n",
    "\n",
    "        # Parse the model's output\n",
    "        parsed_response = self.parser.parse(raw_response).parsed\n",
    "\n",
    "        vectorstore_entry = Msg(\n",
    "            self.name,\n",
    "            content=json.dumps(parsed_response),\n",
    "            role=\"assistant\"\n",
    "        )\n",
    "\n",
    "        # Save the model's response to memory\n",
    "        self.memory.add_message(message=vectorstore_entry)\n",
    "\n",
    "        msg = Msg(\n",
    "            self.name,\n",
    "            content=self.parser.to_content(parsed_response),\n",
    "            role=\"assistant\",\n",
    "            metadata=self.parser.to_metadata(parsed_response),\n",
    "        )\n",
    "        \n",
    "        return msg\n",
    "\n",
    "    def observe(self, x: Union[Msg, Sequence[Msg]], role: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Record incoming messages in memory without generating a reply.\n",
    "\n",
    "        Args:\n",
    "            x (Union[Msg, Sequence[Msg]]): The message(s) to be stored in memory for future context.\n",
    "            role (`str`, optional): Role of the observer\n",
    "        \"\"\"\n",
    "        if role == \"seer\" and x is not None:\n",
    "            self.memory.add_message(message=x)\n",
    "\n",
    "    def save_context(self, game_num: int, player_role: str):\n",
    "        \"\"\"\n",
    "        Save self.messages to a log file in the format:\n",
    "        vectorstore/[timestamp]/[game_num]/[player_role].log\n",
    "\n",
    "        Args:\n",
    "            game_num (int): The game index.\n",
    "            player_role (str): The role of the player.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.memory.save_context(game_num, player_role)\n",
    "\n",
    "\n",
    "# Register your custom classes\n",
    "agentscope.agents.NormalAgent = NormalAgent\n",
    "agentscope.agents.WerewolfAgent = WerewolfAgent\n",
    "agentscope.agents.Lawyer = Lawyer\n",
    "agentscope.agents.Judge = Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts and Parser (edit minimally)\n",
    "Below are the prompts that control and run the Werwolf game. They are implemented using the built in AgentScope MarkdownJsonDictParser which allows us to generate responses in a dictionary format that is compatible with our game. Currently structured to obtain both the private thoughts of an Agent which remain to themselves and showcase their reasoning, and the words that they speak to other agents.\n",
    "\n",
    "Since these prompts control the game logic itself, we should try to limit the prompt edits here to a minimum, but we can make edits to the parser to control the reasoning process a particular role goes through before making a decision, eg. instead of a thought field, we ask it to make ask it to provide a reason to vote for a particular agent, and a reason to not vote for a particular agent, then ask it to make a final decision based off those fields. Fields other than \"thought\" however should not be touched as they play a critical role to the control flow of the game.\n",
    "\n",
    "More details on the AgentScope parsers can be found here https://doc.agentscope.io/build_tutorial/structured_output.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompts:\n",
    "    \"\"\"Prompts for werewolf game\"\"\"\n",
    "\n",
    "    # Lawyer & Judge Architecture\n",
    "\n",
    "    lawyer_prompt = \"\"\"\n",
    "        You are arguing FOR the decision to eliminate {}.\n",
    "        Argue FOR eliminating the player in bullet-point format. Use at most 3 bullets.\n",
    "    \"\"\"\n",
    "    judge_prompt = \"\"\"\n",
    "        You are a judge deciding which player should be eliminated in a game of werewolf. Your goal is to maximize the player's chances of winning the game with forward-thinking reasoning.\n",
    "        \n",
    "        Game State:\n",
    "        - Alive players: {}\n",
    "        - Dead players: {}\n",
    "        - Werewolves: {}\n",
    "\n",
    "        The two lawyers have made their arguments:\n",
    "        - **Lawyer 1** wants to eliminate {}: \"{}\"\n",
    "        - **Lawyer 2** wants to eliminate {}: \"{}\"\n",
    "\n",
    "        Make your final decision: Which player should be eliminated between the 2? Justify your reasoning briefly.\n",
    "    \"\"\"\n",
    "\n",
    "    rules = \"\"\"\n",
    "        Player roles: In werewolf game, players are divided into two werewolves, two villagers, one seer and one witch. Note only werewolves know who are their teammates.\n",
    "        - Werewolves: They know their teammates' identities and attempt to eliminate a villager each night while trying to remain undetected.\n",
    "        - Villagers: They do not know who the werewolves are and must work together during the day to deduce who the werewolves might be and vote to eliminate them.\n",
    "        - Seer: A villager with the ability to learn the true identity of one player each night. This role is crucial for the villagers to gain information.\n",
    "        - Witch: A character who has a one-time ability to save a player from being eliminated at night (sometimes this is a potion of life) and a one-time ability to eliminate a player at night (a potion of death).\n",
    "\n",
    "        Game Rule: The game is consisted of two phases: night phase and day phase. The two phases are repeated until werewolf or villager win the game.\n",
    "        1. Night Phase: During the night, the werewolves discuss and vote for a player to eliminate. Special roles also perform their actions at this time (e.g., the Seer chooses a player to learn their role, the witch chooses a decide if save the player).\n",
    "        2. Day Phase: During the day, all surviving players discuss who they suspect might be a werewolf. No one reveals their role unless it serves a strategic purpose. After the discussion, a vote is taken, and the player with the most votes is \\\"lynched\\\" or eliminated from the game.\n",
    "\n",
    "        Victory Condition: For werewolves, they win the game if the number of werewolves is equal to or greater than the number of remaining villagers. For villagers, they win if they identify and eliminate all of the werewolves in the group.\n",
    "\n",
    "        Constraints:\n",
    "        1. Your response should be in the first person.\n",
    "        2. This is a conversational game. You should response only based on the conversation history and your strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    to_wolves = (\n",
    "        \"{}, if you are the only werewolf, eliminate a player. Otherwise, \"\n",
    "        \"discuss with your teammates and reach an agreement.\"\n",
    "    )\n",
    "\n",
    "    wolves_discuss_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"speak\": \"what you speak\",\n",
    "            \"finish_discussion\": \"whether the discussion reached an agreement or not (true/false)\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"speak\", \"finish_discussion\"],\n",
    "        keys_to_memory=\"speak\",\n",
    "        keys_to_content=\"speak\",\n",
    "        keys_to_metadata=[\"finish_discussion\"],\n",
    "    )\n",
    "\n",
    "    to_wolves_vote = \"Which player do you vote to kill?\"\n",
    "\n",
    "    wolves_vote_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"vote\": \"player_name\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"vote\"],\n",
    "        keys_to_memory=\"vote\",\n",
    "        keys_to_content=\"vote\",\n",
    "    )\n",
    "\n",
    "    to_wolves_res = \"The player with the most votes is {}.\"\n",
    "\n",
    "    to_witch_resurrect = (\n",
    "        \"{witch_name}, you're the witch. Tonight {dead_name} is eliminated. \"\n",
    "        \"Would you like to resurrect {dead_name}?\"\n",
    "    )\n",
    "\n",
    "    to_witch_resurrect_no = \"The witch has chosen not to resurrect the player.\"\n",
    "    to_witch_resurrect_yes = \"The witch has chosen to resurrect the player.\"\n",
    "\n",
    "    witch_resurrect_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"speak\": \"whether to resurrect the player and the reason\",\n",
    "            \"resurrect\": \"whether to resurrect the player or not (true/false)\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"speak\", \"resurrect\"],\n",
    "        keys_to_memory=\"speak\",\n",
    "        keys_to_content=\"speak\",\n",
    "        keys_to_metadata=[\"resurrect\"],\n",
    "    )\n",
    "\n",
    "    to_witch_poison = (\n",
    "        \"Would you like to eliminate one player? If yes, \"\n",
    "        \"specify the player_name.\"\n",
    "    )\n",
    "\n",
    "    witch_poison_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"speak\": \"what you speak\",\n",
    "            \"eliminate\": \"whether to eliminate a player or not (true/false)\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"speak\", \"eliminate\"],\n",
    "        keys_to_memory=\"speak\",\n",
    "        keys_to_content=\"speak\",\n",
    "        keys_to_metadata=[\"eliminate\"],\n",
    "    )\n",
    "\n",
    "    to_seer = (\n",
    "        \"{}, you're the seer. Which player in {} would you like to check \"\n",
    "        \"tonight?\"\n",
    "    )\n",
    "\n",
    "    seer_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"speak\": \"player_name\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"speak\"],\n",
    "        keys_to_memory=\"speak\",\n",
    "        keys_to_content=\"speak\",\n",
    "    )\n",
    "\n",
    "    to_seer_result = \"Okay, the role of {} is a {}.\"\n",
    "\n",
    "    to_all_danger = (\n",
    "        \"The day is coming, all the players open your eyes. Last night, \"\n",
    "        \"the following player(s) has been eliminated: {}.\"\n",
    "    )\n",
    "\n",
    "    to_all_peace = (\n",
    "        \"The day is coming, all the players open your eyes. Last night is \"\n",
    "        \"peaceful, no player is eliminated.\"\n",
    "    )\n",
    "\n",
    "    to_all_discuss = (\n",
    "        \"Now the alive players are {}. Given the game rules and your role, \"\n",
    "        \"based on the situation and the information you gain, to vote a \"\n",
    "        \"player eliminated among alive players and to win the game, what do \"\n",
    "        \"you want to say to others? You can decide whether to reveal your \"\n",
    "        \"role.\"\n",
    "    )\n",
    "\n",
    "    survivors_discuss_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"speak\": \"what you speak\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"speak\"],\n",
    "        keys_to_memory=\"speak\",\n",
    "        keys_to_content=\"speak\",\n",
    "    )\n",
    "\n",
    "    survivors_vote_parser = MarkdownJsonDictParser(\n",
    "        content_hint={\n",
    "            \"thought\": \"what you thought\",\n",
    "            \"vote\": \"player_name\",\n",
    "        },\n",
    "        required_keys=[\"thought\", \"vote\"],\n",
    "        keys_to_memory=\"vote\",\n",
    "        keys_to_content=\"vote\",\n",
    "    )\n",
    "\n",
    "    to_all_vote = (\n",
    "        \"Given the game rules and your role, based on the situation and the\"\n",
    "        \" information you gain, to win the game, it's time to vote one player\"\n",
    "        \" eliminated among the alive players. Which player do you vote to \"\n",
    "        \"kill?\"\n",
    "    )\n",
    "\n",
    "    to_all_res = \"{} has been voted out.\"\n",
    "\n",
    "    to_all_wolf_win = (\n",
    "        \"The werewolves have prevailed and taken over the village. Better \"\n",
    "        \"luck next time!\"\n",
    "    )\n",
    "\n",
    "    to_all_village_win = (\n",
    "        \"The game is over. The werewolves have been defeated, and the village \"\n",
    "        \"is safe once again!\"\n",
    "    )\n",
    "\n",
    "    to_all_continue = \"The game goes on.\"\n",
    "\n",
    "    \n",
    "# Moderator message function\n",
    "HostMsg = partial(Msg, name=\"Moderator\", role=\"assistant\", echo=True)\n",
    "QueryMsg = partial(Msg, name=\"Query\", role=\"user\", echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstore Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries:\n",
    "    \"\"\"Queries for the vectorstore based on certain points in game\"\"\"\n",
    "\n",
    "    # Retrieves discussions about suspicions of non-werewolves to help identify potential enemies.\n",
    "    werewolf_discussion_query = \"Discussions related to villagers, seer, witch.\"\n",
    "\n",
    "    # Retrieves discussions focused on identifying werewolves.\n",
    "    non_werewolf_discussion_query = \"Discussions related to werewolves.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Initialization (edit here)\n",
    "To initialize the agents, you must define their parameters and settings in the config objects that are passed in for initialization. There is a model config, which defines the base foundational model being used, and an agent config, which defines each of the agents being used in the game, including which model their using, their name, and what type of Agent they are (based off the agent classes we defined earlier). \n",
    "\n",
    "Pay particular attention to the system prompt, this is what defines the rules of the game to the agent and gives them the role and what their responsibilities are, we could perhaps do some prompt engineering with that.\n",
    "\n",
    "Also we can play around with the settings of the game, eg. max rounds, how many werewolves we have, etc. Just make sure to update the roles, witch, seer objects below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define the API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions (don't edit)\n",
    "Functions to check and update game state throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_with_fallback(func: Callable[..., Any], *args: Any, **kwargs: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Tries to execute the given function. If it fails, waits 5 seconds and retries once.\n",
    "    If it fails again, exits the script.\n",
    "\n",
    "    Args:\n",
    "        func (Callable[..., Any]): The function to execute.\n",
    "        *args (Any): Positional arguments to pass to the function.\n",
    "        **kwargs (Any): Keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        Any: The result of the function if successful.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return func(*args, **kwargs)  # Try executing the function\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. Retrying in 5 seconds...\")\n",
    "        time.sleep(5)  # Wait 5 seconds before retrying\n",
    "\n",
    "        try:\n",
    "            return func(*args, **kwargs)  # Try again\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Failed again. Stopping execution.\")\n",
    "            sys.exit(1)  # Exit the script if it fails twice\n",
    "\n",
    "\n",
    "def log_separator():\n",
    "    \"\"\"Logs a separator into the log file so it's easier to parse different sections of the game\"\"\"\n",
    "    logger.info(\"===\")\n",
    "\n",
    "def load_json_response(response: str) -> dict:\n",
    "    \"\"\"Converts a json response to a python dictionary\"\"\"\n",
    "    return json.loads(response.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "\n",
    "def convert_messages_to_string(relevant_messages: list) -> str:\n",
    "    \"\"\"Takes a list of messages, and converts them to a string separated by new line\"\"\"\n",
    "    return '\\n'.join([f\"{msg.name}: {msg.content}\" for msg in relevant_messages])\n",
    "\n",
    "def majority_vote(votes: list) -> Any:\n",
    "    \"\"\"Given a list of votes, return the name with the highest frequency.\"\"\"\n",
    "    votes_valid = [v for v in votes if v != \"Abstain\"]\n",
    "    if not votes_valid:\n",
    "        return \"No Votes\"\n",
    "    unique_vals, counts = np.unique(votes_valid, return_counts=True)\n",
    "    return unique_vals[np.argmax(counts)]\n",
    "\n",
    "def update_alive_players(game_state: dict, survivors: list, wolves: list, dead_names):\n",
    "    \"\"\"\n",
    "    Removes 'dead_names' from 'game_state[\"survivors\"]', updates game_state[\"dead\"],\n",
    "    and returns updated survivors and wolves lists.\n",
    "    \"\"\"\n",
    "    if not isinstance(dead_names, list):\n",
    "        dead_names = [dead_names]\n",
    "    for d in dead_names:\n",
    "        if d in game_state[\"survivors\"]:\n",
    "            game_state[\"survivors\"].remove(d)\n",
    "        if d not in game_state[\"dead\"]:\n",
    "            game_state[\"dead\"].append(d)\n",
    "\n",
    "    # Rebuild survivors / wolves lists\n",
    "    new_survivors = [s for s in survivors if s.name in game_state[\"survivors\"]]\n",
    "    new_wolves = [w for w in wolves if w.name in game_state[\"survivors\"]]\n",
    "    return new_survivors, new_wolves\n",
    "\n",
    "def check_winning(game_state: dict, survivors: list, wolves: list, host: str) -> bool:\n",
    "    \"\"\"\n",
    "    If #werewolves * 2 >= #survivors => werewolves instantly win.\n",
    "    If all werewolves are dead => villagers instantly win.\n",
    "    Otherwise => game continues.\n",
    "    \"\"\"\n",
    "    if len(wolves) * 2 >= len(survivors):\n",
    "        msg = Msg(host, Prompts.to_all_wolf_win, role=\"assistant\")\n",
    "        game_state[\"endgame\"] = True\n",
    "        game_state[\"winner\"] = \"werewolves\"\n",
    "        logger.info(f\"Moderator: {Prompts.to_all_wolf_win}\")\n",
    "        log_separator()\n",
    "        return True\n",
    "    if survivors and not wolves:\n",
    "        msg = Msg(host, Prompts.to_all_village_win, role=\"assistant\")\n",
    "        game_state[\"endgame\"] = True\n",
    "        game_state[\"winner\"] = \"villagers\"\n",
    "        logger.info(f\"Moderator: {Prompts.to_all_village_win}\")\n",
    "        log_separator()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def generate_log_filepath(basepath: str, game_num: int) -> str:\n",
    "    \"\"\"Generate log file path with EST timestamp.\"\"\"\n",
    "    est_now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
    "    iso_timestamp = est_now.isoformat(timespec='seconds').replace(\":\", \"-\")\n",
    "    return f\"{basepath}_{game_num}_{iso_timestamp}.log\"\n",
    "\n",
    "def save_results(win_rate_filepath: str, row: dict):\n",
    "    \"\"\"\n",
    "    Append a row to a CSV file. If doesn't exist, create with headers.\n",
    "\n",
    "    row = {\n",
    "      \"raw_log_filepath\": <str>,\n",
    "      \"custom_agent_won\": <bool>,\n",
    "    }\n",
    "    \"\"\"\n",
    "    file_exists = os.path.isfile(win_rate_filepath)\n",
    "    with open(win_rate_filepath, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"raw_log_filepath\", \"custom_agent_won\"])\n",
    "        if not file_exists:\n",
    "            w.writeheader()\n",
    "        w.writerow(row)\n",
    "    print(f\"Row added to {win_rate_filepath}: {row}\")\n",
    "\n",
    "def custom_agent_won(game_state: dict, alive_agents: list, wolf_agents: list):\n",
    "    \"\"\"Records whether custom agent won (even if game didn't complete)\"\"\"\n",
    "\n",
    "    # If game is completed, check if werewolves have won\n",
    "    if game_state[\"endgame\"]:\n",
    "        if game_state[\"winner\"] == \"werewolves\":\n",
    "            return True \n",
    "        return False\n",
    "    \n",
    "    # If game not completed, then custom agent wins because it is still alive and eliminated another player\n",
    "    return True\n",
    "\n",
    "def get_available_targets(survivors: list, wolves: list):\n",
    "    \"\"\"Returns list of currently alive non-werewolves\"\"\"\n",
    "    return [survivor.name for survivor in survivors if survivor not in wolves]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Game (don't edit)\n",
    "Following is a function that game through the various Night and Day phases, taking different actions for each agent based on their roles. Multi agent functionality and communication is facilitated through the AgentScope Pipeline and MsgHub, more detailed documentation found here https://doc.agentscope.io/build_api/agentscope.pipelines.pipeline.html#module-agentscope.pipelines.pipeline and https://doc.agentscope.io/build_api/agentscope.msghub.html#module-agentscope.msghub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(\n",
    "        secondary_model,\n",
    "        max_days_per_game,\n",
    "        reflect_before_vectorstore,\n",
    "        max_werewolf_discussion_round,\n",
    "        wolves,\n",
    "        seer,\n",
    "        witch,\n",
    "        roles,\n",
    "        survivors,\n",
    "        game_state\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Runs a single game, storing logs in game_log. This example merges both\n",
    "    day/night flow, werewolf talk, witch usage, seer usage, etc. Then\n",
    "    saves logs and results.\n",
    "    \"\"\"\n",
    "\n",
    "    for day_i in range(1, max_days_per_game + 1):\n",
    "\n",
    "        # 1) Night Phase: Werewolves discussion\n",
    "        log_separator()\n",
    "        hint = HostMsg(content=Prompts.to_wolves.format(n2s(wolves)))\n",
    "        logger.info(f\"Moderator: {hint.content}\")\n",
    "        with msghub(wolves, announcement=hint) as hub:\n",
    "            set_parsers(wolves, Prompts.wolves_discuss_parser)\n",
    "            for r in range(max_werewolf_discussion_round):\n",
    "                x = retry_with_fallback(lambda: sequentialpipeline(wolves))\n",
    "                logger.info(f\"Werewolves discussion: {x.content}\")\n",
    "                if x.metadata.get(\"finish_discussion\", False):\n",
    "                    break\n",
    "            # Then vote\n",
    "            set_parsers(wolves, Prompts.wolves_vote_parser)\n",
    "            hint_vote = HostMsg(content=Prompts.to_wolves_vote)\n",
    "            logger.info(f\"Moderator: {hint_vote.content}\")\n",
    "            votes = [extract_name_and_id(wolf.lawyer_judge_decision(game_state, get_available_targets(survivors, wolves), hint_vote).content)[0] for wolf in wolves]\n",
    "\n",
    "            voted_out = majority_vote(votes)\n",
    "            dead_player = [voted_out]\n",
    "            logger.info(f\"Moderator: {Prompts.to_wolves_res.format(voted_out)}\")\n",
    "            hub.broadcast(HostMsg(content=Prompts.to_wolves_res.format(voted_out)))\n",
    "\n",
    "        # 2) Witch Decision Night   \n",
    "        log_separator()\n",
    "        healing_used_tonight = False\n",
    "        if witch in survivors:\n",
    "            if not game_state[\"witch_healing_used\"]:\n",
    "                hint = HostMsg(\n",
    "                    content=Prompts.to_witch_resurrect.format_map(\n",
    "                        {\n",
    "                            \"witch_name\": witch.name,\n",
    "                            \"dead_name\": dead_player[0],\n",
    "                        },\n",
    "                    ),\n",
    "                )\n",
    "                logger.info(f\"Moderator: {hint.content}\")\n",
    "                set_parsers(witch, Prompts.witch_resurrect_parser)\n",
    "                \n",
    "                # Capture the witch's resurrection response and log it\n",
    "                resurrection_response = retry_with_fallback(lambda: witch(hint))\n",
    "                logger.info(f\"Witch resurrection response: {resurrection_response.content}\")\n",
    "\n",
    "                if resurrection_response.metadata.get(\"resurrect\", False):\n",
    "                    healing_used_tonight = True\n",
    "                    dead_player.pop()\n",
    "                    game_state[\"witch_healing_used\"] = True\n",
    "                    HostMsg(content=Prompts.to_witch_resurrect_yes)\n",
    "                    logger.info(f\"Moderator: {Prompts.to_witch_resurrect_yes}\")\n",
    "                else:\n",
    "                    HostMsg(content=Prompts.to_witch_resurrect_no)\n",
    "                    logger.info(f\"Moderator: {Prompts.to_witch_resurrect_no}\")\n",
    "\n",
    "            if not game_state[\"witch_poison_used\"] and not healing_used_tonight:\n",
    "                set_parsers(witch, Prompts.witch_poison_parser)\n",
    "                \n",
    "                # Capture the witch's poison response and log it\n",
    "                poison_response = retry_with_fallback(lambda: witch(HostMsg(content=Prompts.to_witch_poison)))\n",
    "                logger.info(f\"Witch poison response: {poison_response.content}\")\n",
    "\n",
    "                if poison_response.metadata.get(\"eliminate\", False):\n",
    "                    target_player = extract_name_and_id(poison_response.content)[0]\n",
    "                    dead_player.append(target_player)\n",
    "                    game_state[\"witch_poison_used\"] = True\n",
    "                    logger.info(f\"Moderator: The witch has chosen to poison {target_player}.\")\n",
    "\n",
    "        # 3) Seer checks a role\n",
    "        log_separator()\n",
    "        if seer in survivors:\n",
    "            seer_hint = HostMsg(content=Prompts.to_seer.format(seer.name, n2s(survivors)))\n",
    "            logger.info(f\"Moderator: {seer_hint.content}\")\n",
    "            set_parsers(seer, Prompts.seer_parser)\n",
    "\n",
    "            x = seer.reply(seer_hint) # Use seer hint as query\n",
    "            logger.info(f\"Seer response: {x.content}\")\n",
    "            pl, idx = extract_name_and_id(x.content)\n",
    "            role_name = roles[idx] if idx < len(roles) else \"villager\"\n",
    "            # Let seer quietly observe the result\n",
    "            role_msg = HostMsg(content=Prompts.to_seer_result.format(pl, role_name))\n",
    "            logger.info(f\"Moderator: {role_msg.content}\")\n",
    "            seer.observe(role_msg, \"seer\")\n",
    "\n",
    "        # 4) Update survivors after night\n",
    "        survivors, wolves = update_alive_players(game_state, survivors, wolves, dead_player)\n",
    "        if check_winning(game_state, survivors, wolves, \"Moderator\"):\n",
    "            break\n",
    "\n",
    "        # If reflecting, do a night reflection\n",
    "        if reflect_before_vectorstore:\n",
    "            for w in wolves:\n",
    "                w.summarize_cycle(survivors, secondary_model)\n",
    "\n",
    "        # 5) Daytime discussion\n",
    "        log_separator()\n",
    "        content = (\n",
    "            Prompts.to_all_danger.format(n2s(dead_player))\n",
    "            if dead_player\n",
    "            else Prompts.to_all_peace\n",
    "        )\n",
    "        discuss_hints = [\n",
    "            HostMsg(content=content),\n",
    "            HostMsg(content=Prompts.to_all_discuss.format(n2s(survivors))),\n",
    "        ]\n",
    "        with msghub(survivors, announcement=discuss_hints) as hub:\n",
    "            set_parsers(survivors, Prompts.survivors_discuss_parser)\n",
    "            discussion_out = retry_with_fallback(lambda: sequentialpipeline(survivors))\n",
    "            logger.info(f\"Survivors discussion: {discussion_out.content}\")\n",
    "\n",
    "            # Daytime vote\n",
    "            set_parsers(survivors, Prompts.survivors_vote_parser)\n",
    "            day_vote_hint = HostMsg(content=Prompts.to_all_vote)\n",
    "            logger.info(f\"Moderator: {day_vote_hint.content}\")\n",
    "            \n",
    "            votes_day = [\n",
    "                extract_name_and_id(wolf.lawyer_judge_decision(game_state, get_available_targets(survivors, wolves), day_vote_hint).content)[0] for wolf in wolves\n",
    "            ]\n",
    "\n",
    "            votes_day.extend([\n",
    "                extract_name_and_id(_.reply(day_vote_hint).content)[0] for _ in survivors if _ not in wolves\n",
    "            ])\n",
    "            day_result = majority_vote(votes_day)\n",
    "            logger.info(f\"Daytime vote: {day_result}\")\n",
    "            hub.broadcast(HostMsg(content=Prompts.to_all_res.format(day_result)))\n",
    "\n",
    "            survivors, wolves = update_alive_players(game_state, survivors, wolves, day_result)\n",
    "            if check_winning(game_state, survivors, wolves, \"Moderator\"):\n",
    "                break\n",
    "\n",
    "            # If reflecting, do a day reflection\n",
    "            if reflect_before_vectorstore:\n",
    "                for w in wolves:\n",
    "                    w.summarize_cycle(survivors, secondary_model)\n",
    "\n",
    "            hub.broadcast(HostMsg(content=Prompts.to_all_continue))\n",
    "    \n",
    "    return custom_agent_won(\n",
    "            game_state,\n",
    "            survivors,\n",
    "            wolves\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    open_ai_key: str,\n",
    "    raw_log_filepath: str,\n",
    "    win_rate_filepath: str,\n",
    "    max_days_per_game: int = 10,\n",
    "    num_games: int = 10,\n",
    "    reflect_before_vectorstore: bool = True,\n",
    "    primary_model: str = \"gpt-4o-mini\",\n",
    "    secondary_model: str=\"gpt-4o\",\n",
    "    max_werewolf_discussion_round: int = 3,\n",
    "    similarity_top_k: int = 1\n",
    ") -> None:  \n",
    "    \"\"\"\n",
    "    Initialize and run multiple games of the Werewolf simulation.\n",
    "\n",
    "    Arguments:\n",
    "        open_ai_key (`str`):\n",
    "            The OpenAI API key used for model calls.\n",
    "        raw_log_filepath (`str`):\n",
    "            Base path for logs, e.g., \"logs/game_raw\".\n",
    "        win_rate_filepath (`str`):\n",
    "            CSV file to store results, e.g., \"results.csv\".\n",
    "        max_days_per_game (`int`, defaults to `3`):\n",
    "            Maximum number of day/night cycles per game.\n",
    "        num_games (`int`, defaults to `2`):\n",
    "            Number of games to simulate.\n",
    "        reflect_before_vectorstore (`bool`, defaults to `False`):\n",
    "            Whether to use reflective memory before vectorstore retrieval.\n",
    "        primary_model (`str`, defaults to `\"gpt-4o-mini\"`):\n",
    "            Name of the model used for fast processing.\n",
    "        max_werewolf_discussion_round (`int`, defaults to `3`):\n",
    "            Maximum number of discussion rounds for werewolves.\n",
    "        similarity_top_k (`int`, defaults to `1`):\n",
    "            Number of messages or summaries retrieved from memory.\n",
    "\n",
    "    Returns:\n",
    "        `None`\n",
    "    \"\"\"\n",
    "    # Set openai api key\n",
    "    openai.api_key = open_ai_key\n",
    "\n",
    "    # Define model configs and settings\n",
    "    model_configs = [\n",
    "        {\n",
    "            \"model_type\": \"openai_chat\",\n",
    "            \"config_name\": primary_model,\n",
    "            \"model_name\": primary_model,\n",
    "            \"api_key\": open_ai_key,\n",
    "            \"generate_args\": {\n",
    "                \"temperature\": 1,\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Define the config settings for each agent involved\n",
    "    agent_configs = [\n",
    "        {\n",
    "            \"class\": \"WerewolfAgent\",\n",
    "            \"args\": {\n",
    "                \"name\": \"Player1\",\n",
    "                \"sys_prompt\": f\"\"\"\n",
    "                    You are a strategic decision-maker playing a game of werewolf.\n",
    "\n",
    "                    You are Player1 and there are totally 4 players, named Player1, Player2, Player3, Player4.\n",
    "                    \n",
    "                    Rules of the game:\n",
    "\n",
    "                    {Prompts.rules}\n",
    "                    \n",
    "                    You are playing werewolf in this game.\n",
    "                \"\"\",\n",
    "                \"model_config_name\": primary_model,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"similarity_top_k\": similarity_top_k,\n",
    "                \"openai_api_key\": open_ai_key\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"NormalAgent\",\n",
    "            \"args\": {\n",
    "                \"name\": \"Player2\",\n",
    "                \"sys_prompt\": f\"\"\" \n",
    "                    You are a strategic decision-maker playing a game of werewolf.\n",
    "\n",
    "                    You are Player2 and there are totally 4 players, named Player1, Player2, Player3, Player4.\n",
    "\n",
    "                    Rules of the game: \n",
    "                \n",
    "                    {Prompts.rules}\n",
    "                    \n",
    "                    You are playing villager in this game.\n",
    "                \"\"\",\n",
    "                \"model_config_name\": primary_model,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"similarity_top_k\": similarity_top_k,\n",
    "                \"openai_api_key\": open_ai_key\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"NormalAgent\",\n",
    "            \"args\": {\n",
    "                \"name\": \"Player3\",\n",
    "                \"sys_prompt\": f\"\"\" \n",
    "                    You are a strategic decision-maker playing a game of werewolf.\n",
    "\n",
    "                    You are Player3 and there are totally 4 players, named Player1, Player2, Player3, Player4.\n",
    "\n",
    "                    Rules of the game:\n",
    "\n",
    "                    {Prompts.rules}\n",
    "                    \n",
    "                    You are playing seer in this game.\n",
    "                \"\"\",\n",
    "                \"model_config_name\": primary_model,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"similarity_top_k\": similarity_top_k,\n",
    "                \"openai_api_key\": open_ai_key\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"NormalAgent\",\n",
    "            \"args\": {\n",
    "                \"name\": \"Player4\",\n",
    "                \"sys_prompt\": f\"\"\" \n",
    "                    You are a strategic decision-maker playing a game of werewolf.\n",
    "                    \n",
    "                    You are Player4 and there are totally 4 players, named Player1, Player2, Player3, Player4.\n",
    "                    \n",
    "                    Rules of the game:\n",
    "\n",
    "                    {Prompts.rules}\n",
    "                    \n",
    "                    You are playing witch in this game.\n",
    "                \"\"\",\n",
    "                \"model_config_name\": primary_model,\n",
    "                \"reflect_before_vectorstore\": reflect_before_vectorstore,\n",
    "                \"similarity_top_k\": 1,\n",
    "                \"openai_api_key\": open_ai_key\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for game_num in range(1, num_games + 1):\n",
    "\n",
    "        # Read model and agent configs, and initialize agents automatically\n",
    "        survivors = agentscope.init(\n",
    "            model_configs=model_configs,\n",
    "            agent_configs=agent_configs,\n",
    "            project=\"Werewolf\",\n",
    "        )\n",
    "\n",
    "        # Get player roles\n",
    "        roles = [\"werewolf\", \"villager\", \"seer\", \"witch\"]\n",
    "        wolves, witch, seer, villagers = [survivors[0]], survivors[-1], survivors[-2], [survivors[-3]]\n",
    "\n",
    "        # Initialize game state\n",
    "        game_state = {\n",
    "            \"werewolves\": [player.name for player in wolves],\n",
    "            \"villagers\": [player.name for player in survivors if player not in wolves],\n",
    "            \"seer\": [seer.name],\n",
    "            \"witch\": [witch.name],\n",
    "            \"survivors\": [player.name for player in survivors],\n",
    "            \"dead\": [],\n",
    "            \"witch_healing_used\": False,\n",
    "            \"witch_poison_used\": False,\n",
    "            \"endgame\": False,\n",
    "            \"winner\": None\n",
    "            \n",
    "        }\n",
    "\n",
    "        current_log_path = generate_log_filepath(raw_log_filepath, game_num)\n",
    "        change_log_file(current_log_path)\n",
    "\n",
    "        # Log parameters\n",
    "        log_params(\n",
    "            current_log_path, \n",
    "            primary_model=primary_model, \n",
    "            secondary_model=secondary_model,\n",
    "            raw_log_filepath=raw_log_filepath, \n",
    "            win_rate_filepath=win_rate_filepath, \n",
    "            max_days_per_game=max_days_per_game, \n",
    "            num_games=num_games,\n",
    "            reflect_before_vectorstore=reflect_before_vectorstore, \n",
    "            max_werewolf_discussion_round=max_werewolf_discussion_round, \n",
    "            similarity_top_k=similarity_top_k\n",
    "        )\n",
    "\n",
    "        custom_agent_won = run_game(\n",
    "            secondary_model,\n",
    "            max_days_per_game,\n",
    "            reflect_before_vectorstore,\n",
    "            max_werewolf_discussion_round,\n",
    "            wolves,\n",
    "            seer,\n",
    "            witch,\n",
    "            roles,\n",
    "            survivors,\n",
    "            game_state\n",
    "        )\n",
    "\n",
    "        wolves[0].save_context(game_num)\n",
    "        witch.save_context(game_num, \"witch\")\n",
    "        seer.save_context(game_num, \"seer\")\n",
    "        villagers[0].save_context(game_num, \"villager\")\n",
    "\n",
    "\n",
    "        row = {\n",
    "            \"raw_log_filepath\": current_log_path,\n",
    "            \"custom_agent_won\": custom_agent_won\n",
    "        }\n",
    "        save_results(win_rate_filepath, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:09:52 | INFO     | agentscope.manager._model:load_model_configs:115 - Load configs for model wrapper: gpt-4o-mini\n",
      "2025-02-23 22:09:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:09:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:09:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:09:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:09:52 - INFO - ===\n",
      "2025-02-23 22:09:52 - INFO - Moderator: Player1, if you are the only werewolf, eliminate a player. Otherwise, discuss with your teammates and reach an agreement.\n",
      "2025-02-23 22:09:52 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters written to test/courtroom_raw_1_2025-02-23T22-09-52-05-00.log\n",
      "\u001b[93mModerator\u001b[0m: Player1, if you are the only werewolf, eliminate a player. Otherwise, discuss with your teammates and reach an agreement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:09:54 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:09:54 - INFO - Werewolves discussion: I think we should consider Player2's behavior yesterday. They seemed quite reserved and didn't contribute much to our discussion. That makes me suspicious of them.\n",
      "2025-02-23 22:09:54 - INFO - Moderator: Which player do you vote to kill?\n",
      "2025-02-23 22:09:54 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I need to protect my identity as a werewolf while also trying to frame one of the villagers. I should cast suspicion on Player2 who has been quiet during discussions.\", \"speak\": \"I think we should consider Player2's behavior yesterday. They seemed quite reserved and didn't contribute much to our discussion. That makes me suspicious of them.\", \"finish_discussion\": \"false\"}\n",
      "```\n",
      "\u001b[93mModerator\u001b[0m: Which player do you vote to kill?\n",
      "2025-02-23 22:09:54 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:55 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:09:55 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:55 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:09:55 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:09:55 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:09:56 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:09:57 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:09:58 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:09:58 - INFO - Lawyer 1 argument: {'target': 'Player3', 'argument': {'thought': \"Player3 has been acting suspiciously and hasn't contributed much to the discussions, which raises red flags for me. Their silence could be a tactic to avoid drawing attention as a werewolf.\", 'vote': 'Player3'}}\n",
      "2025-02-23 22:09:58 - INFO - Lawyer 2 argument: {'target': 'Player4', 'argument': {'thought': 'Player4 has been acting suspiciously by not participating in discussions and avoiding direct accusations toward anyone. This lack of engagement raises red flags about their intentions.', 'vote': 'Player4'}}\n",
      "2025-02-23 22:09:58 - INFO - Judge decision: {'thought': 'Both Player3 and Player4 are exhibiting suspicious behavior through their lack of participation, but Player3 has been singled out more specifically by Lawyer 1 for their silence and lack of contributions. It might be strategic to eliminate a player who is less engaged, as this could uncover more potential werewolves. Therefore, I lean towards eliminating Player3 as their behavior is more pointedly suspicious.', 'vote': 'Player3'}\n",
      "2025-02-23 22:09:58 - INFO - Moderator: The player with the most votes is Player3.\n",
      "2025-02-23 22:09:58 - INFO - ===\n",
      "2025-02-23 22:09:58 - INFO - Moderator: Player4, you're the witch. Tonight Player3 is eliminated. Would you like to resurrect Player3?\n",
      "2025-02-23 22:09:58 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"Both Player3 and Player4 are exhibiting suspicious behavior through their lack of participation, but Player3 has been singled out more specifically by Lawyer 1 for their silence and lack of contributions. It might be strategic to eliminate a player who is less engaged, as this could uncover more potential werewolves. Therefore, I lean towards eliminating Player3 as their behavior is more pointedly suspicious.\", \"vote\": \"Player3\"}\n",
      "```\n",
      "\u001b[93mModerator\u001b[0m: The player with the most votes is Player3.\n",
      "\u001b[93mModerator\u001b[0m: Player4, you're the witch. Tonight Player3 is eliminated. Would you like to resurrect Player3?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:00 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"I need to consider the implications of resurrecting Player3. If they were eliminated by the werewolves, we can potentially gain valuable information about their role. However, if they have become a target or the werewolves' suspicions, it may not be wise to resurrect them immediately.\", \"speak\": \"I believe I should resurrect Player3. Even though they've been eliminated, having them back might give us insights into the players' roles and voting patterns during the previous day. We need as much information as possible to vote wisely.\", \"resurrect\": true}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:00 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:00 - INFO - Witch resurrection response: I believe I should resurrect Player3. Even though they've been eliminated, having them back might give us insights into the players' roles and voting patterns during the previous day. We need as much information as possible to vote wisely.\n",
      "2025-02-23 22:10:00 - INFO - Moderator: The witch has chosen to resurrect the player.\n",
      "2025-02-23 22:10:00 - INFO - ===\n",
      "2025-02-23 22:10:00 - INFO - Moderator: Player3, you're the seer. Which player in Player1, Player2, Player3 and Player4 would you like to check tonight?\n",
      "2025-02-23 22:10:00 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: The witch has chosen to resurrect the player.\n",
      "\u001b[93mModerator\u001b[0m: Player3, you're the seer. Which player in Player1, Player2, Player3 and Player4 would you like to check tonight?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:01 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to check Player4 tonight. They could hold valuable information, and it's essential to know if they are a werewolf or a villager.\",\"speak\": \"Player4\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:02 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:02 - INFO - Seer response: Player4\n",
      "2025-02-23 22:10:02 - INFO - Moderator: Okay, the role of Player4 is a witch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Okay, the role of Player4 is a witch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:02 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:16 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:16 - INFO - ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: The day is coming, all the players open your eyes. Last night is peaceful, no player is eliminated.\n",
      "\u001b[93mModerator\u001b[0m: Now the alive players are Player1, Player2, Player3 and Player4. Given the game rules and your role, based on the situation and the information you gain, to vote a player eliminated among alive players and to win the game, what do you want to say to others? You can decide whether to reveal your role.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:16 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:16 - INFO - Relevant messages from vectorstore: Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n",
      "Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n",
      "2025-02-23 22:10:18 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:18 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I need to keep diverting attention away from myself and continue framing Player2 as suspicious. They are quiet, making them an easy target. At the same time, I should also watch out for Player4, who seems to be catching on. It's crucial to maintain my cover and not draw suspicion to myself too much.\", \"speak\": \"I think we should consider eliminating Player2. Their silence is a bit unnerving, and they haven't contributed much to our discussions. It seems like they're trying to avoid drawing attention to themselves. What does everyone else think?\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:20 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer2\u001b[0m: ```json\n",
      "{\"thought\": \"Player1 seems to be trying to divert attention towards me. This could be a tactic to protect a werewolf partner or shift focus. I need to defend myself and encourage more dialogue from the group to draw out potential werewolves.\", \"speak\": \"I understand your concern, Player1, but I can assure you I'm just as invested in finding the werewolves as you are. Maybe we should discuss everyone's suspicions and observations before jumping to conclusions about me or anyone else.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:20 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:21 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:21 - INFO - Relevant messages from vectorstore: Player3: {\"thought\": \"I need to check Player4 tonight. They could hold valuable information, and it's essential to know if they are a werewolf or a villager.\", \"speak\": \"Player4\"}\n",
      "Moderator: Okay, the role of Player4 is a witch.\n",
      "2025-02-23 22:10:22 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to keep my role as the Seer a secret while guiding the conversation towards identifying the werewolves. I want to make sure that Player2 isn't a wolf and gather more information from Player1 and Player4's responses.\",\"speak\": \"I think it's crucial that we all share our thoughts on who we suspect might be a werewolf. Let's each take a turn and share any observations we might have.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:22 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:23 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:23 - INFO - Relevant messages from vectorstore: Player4: {\"thought\": \"I need to consider the implications of resurrecting Player3. If they were eliminated by the werewolves, we can potentially gain valuable information about their role. However, if they have become a target or the werewolves' suspicions, it may not be wise to resurrect them immediately.\", \"speak\": \"I believe I should resurrect Player3. Even though they've been eliminated, having them back might give us insights into the players' roles and voting patterns during the previous day. We need as much information as possible to vote wisely.\", \"resurrect\": true}\n",
      "2025-02-23 22:10:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"I need to be careful about revealing my role but share some suspicions to gain trust. I should also listen closely to what others say, as they might drop clues about their identities.\", \"speak\": \"I agree, sharing our thoughts is important. From what I've seen, Player2 has been a bit more reserved than usual. What does everyone else think?”}\n",
      "```\n",
      "Error: JsonParsingError: The content between ```json and ``` MUST be a JSON object.When parsing \"```json\n",
      "{\"thought\": \"I need to be careful about revealing my role but share some suspicions to gain trust. I should also listen closely to what others say, as they might drop clues about their identities.\", \"speak\": \"I agree, sharing our thoughts is important. From what I've seen, Player2 has been a bit more reserved than usual. What does everyone else think?”}\n",
      "```\", an error occurred: Invalid control character at: line 2 column 356 (char 356). Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:30 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:30 - INFO - Relevant messages from vectorstore: Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n",
      "Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n",
      "2025-02-23 22:10:32 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I need to maintain my cover while pointing suspicion towards Player2 again. I've noticed they're still not participating much, which might give credence to my claims. I should also keep an eye on Player4 and Player3 for any signs of a seer or witch role since they might pose a threat if they start making accusations.\",\"speak\": \"I've been thinking a lot about how quiet Player2 has been. It really makes me wonder if they're trying to avoid drawing attention to themselves. Maybe we should consider them for elimination. Also, Player3 and Player4 haven't been contributing much either; it's suspicious behavior that we should discuss.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:32 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:32 - INFO - Relevant messages from vectorstore: Player2: {\"thought\": \"Player1 seems to be trying to divert attention towards me. This could be a tactic to protect a werewolf partner or shift focus. I need to defend myself and encourage more dialogue from the group to draw out potential werewolves.\", \"speak\": \"I understand your concern, Player1, but I can assure you I'm just as invested in finding the werewolves as you are. Maybe we should discuss everyone's suspicions and observations before jumping to conclusions about me or anyone else.\"}\n",
      "Player2: {\"thought\": \"Player1 seems to be trying to divert attention towards me. This could be a tactic to protect a werewolf partner or shift focus. I need to defend myself and encourage more dialogue from the group to draw out potential werewolves.\", \"speak\": \"I understand your concern, Player1, but I can assure you I'm just as invested in finding the werewolves as you are. Maybe we should discuss everyone's suspicions and observations before jumping to conclusions about me or anyone else.\"}\n",
      "2025-02-23 22:10:34 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer2\u001b[0m: ```json\n",
      "{\"thought\": \"Player1 is pointing fingers at me, which could be a tactic to divert attention from themselves. I need to defend my position while also getting insights from Player3 and Player4 about their thoughts on Player1's claims.\", \"speak\": \"I understand your concerns about my quietness, Player1, but my strategy has been to observe and analyze. I think we should also consider Player3 and Player4 in this discussion. What are your thoughts on them?\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:35 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:36 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:36 - INFO - Relevant messages from vectorstore: Player3: {\"thought\": \"I need to keep my role as the Seer a secret while guiding the conversation towards identifying the werewolves. I want to make sure that Player2 isn't a wolf and gather more information from Player1 and Player4's responses.\", \"speak\": \"I think it's crucial that we all share our thoughts on who we suspect might be a werewolf. Let's each take a turn and share any observations we might have.\"}\n",
      "Player3: {\"thought\": \"I need to check Player4 tonight. They could hold valuable information, and it's essential to know if they are a werewolf or a villager.\", \"speak\": \"Player4\"}\n",
      "2025-02-23 22:10:37 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"Player2 seems to be trying to divert attention from themselves and downplay their quietness. I need to keep an eye on both Player1 and Player2 to see if they truly contribute beneficial insights or just deflect in order to appear less suspicious.\", \"speak\": \"I think it's important for us to focus on the behaviors of all players, including Player3 and Player4. They may provide hidden clues about who the werewolves are. What specific actions from them have raised suspicions for you?\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:38 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:38 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:38 - INFO - Relevant messages from vectorstore: Player4: {\"thought\": \"I need to consider the implications of resurrecting Player3. If they were eliminated by the werewolves, we can potentially gain valuable information about their role. However, if they have become a target or the werewolves' suspicions, it may not be wise to resurrect them immediately.\", \"speak\": \"I believe I should resurrect Player3. Even though they've been eliminated, having them back might give us insights into the players' roles and voting patterns during the previous day. We need as much information as possible to vote wisely.\", \"resurrect\": true}\n",
      "2025-02-23 22:10:40 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"I need to steer the conversation toward identifying players without giving away my role as the witch. It's crucial for me to gauge everyone's suspicions and build trust while gathering information.\", \"speak\": \"I agree, Player3. Observing each other's behavior might give us some insights. I've noticed that some players seem a bit more defensive in their arguments. That could be a sign of something. What about you, Player1? Have you noticed anything particular?\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:40 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:40 - INFO - Survivors discussion: I agree, Player3. Observing each other's behavior might give us some insights. I've noticed that some players seem a bit more defensive in their arguments. That could be a sign of something. What about you, Player1? Have you noticed anything particular?\n",
      "2025-02-23 22:10:40 - INFO - Moderator: Given the game rules and your role, based on the situation and the information you gain, to win the game, it's time to vote one player eliminated among the alive players. Which player do you vote to kill?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Given the game rules and your role, based on the situation and the information you gain, to win the game, it's time to vote one player eliminated among the alive players. Which player do you vote to kill?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:40 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:40 - INFO - Relevant messages from vectorstore: Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n",
      "Based on the actions and thoughts of Player1, we observe several strategic decisions executed under the guise of suspicion:\n",
      "\n",
      "1. **Protection of Identity**: Player1, a werewolf, attempts to protect their identity by diverting attention towards others, specifically targeting Player2 initially due to their quiet behavior. This demonstrates a common strategy wherein werewolves aim to blend in with villagers by casting doubt upon others.\n",
      "\n",
      "2. **Target Selection and Framing**: Player1 frames Player2 by highlighting their quiet demeanor. This can often stigmatize certain behaviors (e.g., being reserved) and disrupt collaboration among the group. Furthermore, in arguments against Player3 and Player4, Player1 leverages the suspicion around inactivity or non-contribution. Such behavior is often perceived as indicative of a player with something to hide, thus an effective scapegoat.\n",
      "\n",
      "3. **Decision-Making Tactics**: In the decision phase, Player1 weighs the suspicious actions of Player3 and Player4 and opts for a strategic elimination of Player3. This decision is based on the perceived level of suspicious activity (or lack thereof) that Player3 exhibited compared to Player4. The focus on eliminating players with fewer contributions reduces the risk for the werewolves, as quiet players are less likely to successfully counter-argue or shift blame.\n",
      "\n",
      "### Implications for Future Strategic Decisions:\n",
      "\n",
      "- **Suspicion Management**: Future strategy should continue to employ suspicion deflection onto quieter players, as this can effectively split the attention of villagers and minimize scrutiny on oneself, particularly for roles needing anonymity like werewolves.\n",
      "\n",
      "- **Behavioral Manipulation**: Pay close attention to player contributions to discussions. Non-participation should be strategically highlighted as a potential werewolf trait. However, adaptability is key. If the group starts recognizing this pattern, consideration for more creative suspicion casting becomes necessary.\n",
      "\n",
      "- **Preemptive Shielding**: Recognize when a player could potentially expose a significant threat and act fast to frame or eliminate them early. This is particularly crucial in cases where the player exhibits analytical behavior that could dismantle a werewolf's strategic attempts.\n",
      "\n",
      "By honing in on these areas, especially the management of group dynamics and careful orchestration of discussions, strategic players can better navigate complex social interactions and enhance their decision-making efficiency in future games.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:40 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:40 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:40 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:40 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:40 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:40 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:41 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:43 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:44 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:44 - INFO - Lawyer 1 argument: {'target': 'Player4', 'argument': {'thought': \"Player4 has been suspiciously quiet and hasn't contributed much to the discussion, which makes them a potential threat as they could be hiding their true identity. Eliminating them could reduce the risk of losing a villager, as their lack of input suggests they might be a werewolf. Additionally, focusing on Player4 could help steer suspicion away from ourselves, ensuring we stay under the radar.\", 'vote': 'Player4'}}\n",
      "2025-02-23 22:10:44 - INFO - Lawyer 2 argument: {'target': 'Player3', 'argument': {'thought': \"Player3 has been unusually quiet and hasn't contributed much to the discussion. This lack of participation raises suspicion and could indicate they are trying to avoid drawing attention to themselves as a werewolf. Eliminating them could reduce the risk to us and help identify the remaining villagers.\", 'vote': 'Player3'}}\n",
      "2025-02-23 22:10:44 - INFO - Judge decision: {'thought': 'Both Player3 and Player4 are being accused of being quiet, which could indicate they are trying to avoid detection. However, since they both have the same level of involvement in the discussion, I will lean towards eliminating Player4. This is because the argument against them suggests that their quietness is a potential cover for hiding their identity as a werewolf, which makes them a higher risk. Eliminating Player4 could help the villagers reduce uncertainty in the future votes.', 'vote': 'Player4'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"Both Player3 and Player4 are being accused of being quiet, which could indicate they are trying to avoid detection. However, since they both have the same level of involvement in the discussion, I will lean towards eliminating Player4. This is because the argument against them suggests that their quietness is a potential cover for hiding their identity as a werewolf, which makes them a higher risk. Eliminating Player4 could help the villagers reduce uncertainty in the future votes.\", \"vote\": \"Player4\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:45 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:45 - INFO - Relevant messages from vectorstore: Player2: {\"thought\": \"Player1 seems to be trying to divert attention towards me. This could be a tactic to protect a werewolf partner or shift focus. I need to defend myself and encourage more dialogue from the group to draw out potential werewolves.\", \"speak\": \"I understand your concern, Player1, but I can assure you I'm just as invested in finding the werewolves as you are. Maybe we should discuss everyone's suspicions and observations before jumping to conclusions about me or anyone else.\"}\n",
      "Player2: {\"thought\": \"Player1 is pointing fingers at me, which could be a tactic to divert attention from themselves. I need to defend my position while also getting insights from Player3 and Player4 about their thoughts on Player1's claims.\", \"speak\": \"I understand your concerns about my quietness, Player1, but my strategy has been to observe and analyze. I think we should also consider Player3 and Player4 in this discussion. What are your thoughts on them?\"}\n",
      "2025-02-23 22:10:46 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer2\u001b[0m: ```json\n",
      "{\"thought\": \"I need to analyze the discussions and actions of the players to figure out who might be the werewolves. I suspect Player3 based on their statements; they seem to deflect suspicion.\", \"vote\": \"Player3\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:46 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:46 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:46 - INFO - Relevant messages from vectorstore: Player3: {\"thought\": \"I need to keep my role as the Seer a secret while guiding the conversation towards identifying the werewolves. I want to make sure that Player2 isn't a wolf and gather more information from Player1 and Player4's responses.\", \"speak\": \"I think it's crucial that we all share our thoughts on who we suspect might be a werewolf. Let's each take a turn and share any observations we might have.\"}\n",
      "Player3: {\"thought\": \"I need to check Player4 tonight. They could hold valuable information, and it's essential to know if they are a werewolf or a villager.\", \"speak\": \"Player4\"}\n",
      "2025-02-23 22:10:47 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to be cautious in voting, but I suspect Player1 based on their behavior. They seem to be trying to deflect attention from themselves, which is a common tactic for a werewolf.\", \"vote\": \"Player1\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:48 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:48 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:48 - INFO - Relevant messages from vectorstore: Player4: {\"thought\": \"I need to consider the implications of resurrecting Player3. If they were eliminated by the werewolves, we can potentially gain valuable information about their role. However, if they have become a target or the werewolves' suspicions, it may not be wise to resurrect them immediately.\", \"speak\": \"I believe I should resurrect Player3. Even though they've been eliminated, having them back might give us insights into the players' roles and voting patterns during the previous day. We need as much information as possible to vote wisely.\", \"resurrect\": true}\n",
      "2025-02-23 22:10:50 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"I have to be strategic about my vote, considering that I need to protect potential villagers while also eliminating a werewolf. Since I haven’t gained any specific information as the witch yet, I will vote for Player1, as they seem the least engaged in the discussion and could be hiding something.\", \"vote\": \"Player1\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:51 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:51 - INFO - Daytime vote: Player1\n",
      "2025-02-23 22:10:51 - INFO - Moderator: The game is over. The werewolves have been defeated, and the village is safe once again!\n",
      "2025-02-23 22:10:51 - INFO - ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Player1 has been voted out.\n",
      "Messages saved to vectorstore/2025-02-23T22-10-51-05-00/1/werewolf.log\n",
      "Messages saved to vectorstore/2025-02-23T22-10-51-05-00/1/witch.log\n",
      "Messages saved to vectorstore/2025-02-23T22-10-51-05-00/1/seer.log\n",
      "Messages saved to vectorstore/2025-02-23T22-10-51-05-00/1/villager.log\n",
      "Row added to test.txt: {'raw_log_filepath': 'test/courtroom_raw_1_2025-02-23T22-09-52-05-00.log', 'custom_agent_won': False}\n",
      "2025-02-23 22:10:51 | WARNING  | agentscope.manager._model:load_model_configs:108 - config_name [gpt-4o-mini] already exists.\n",
      "2025-02-23 22:10:51 | INFO     | agentscope.manager._model:load_model_configs:115 - Load configs for model wrapper: gpt-4o-mini\n",
      "2025-02-23 22:10:51 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:51 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:51 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:51 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:51 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:51 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:51 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:51 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:51 - INFO - ===\n",
      "2025-02-23 22:10:51 - INFO - Moderator: Player1, if you are the only werewolf, eliminate a player. Otherwise, discuss with your teammates and reach an agreement.\n",
      "2025-02-23 22:10:51 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters written to test/courtroom_raw_2_2025-02-23T22-10-51-05-00.log\n",
      "\u001b[93mModerator\u001b[0m: Player1, if you are the only werewolf, eliminate a player. Otherwise, discuss with your teammates and reach an agreement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:52 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:52 - INFO - Werewolves discussion: I think we should focus on who has been acting a bit off lately. I’ve noticed Player2 has been quite defensive and hasn’t contributed much to the discussions. What do others think?\n",
      "2025-02-23 22:10:52 - INFO - Moderator: Which player do you vote to kill?\n",
      "2025-02-23 22:10:52 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I need to play carefully to maintain my cover as a villager while subtly steering the discussion toward Player2 or Player3, who seem more suspect.\", \"speak\": \"I think we should focus on who has been acting a bit off lately. I’ve noticed Player2 has been quite defensive and hasn’t contributed much to the discussions. What do others think?\", \"finish_discussion\": \"false\"}\n",
      "```\n",
      "\u001b[93mModerator\u001b[0m: Which player do you vote to kill?\n",
      "2025-02-23 22:10:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:10:52 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:10:52 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:54 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:56 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:56 - INFO - Lawyer 1 argument: {'target': 'Player3', 'argument': {'thought': \"Player3 has been acting suspiciously, frequently shifting blame to others without substantial evidence. Their behavior could indicate they're trying to deflect attention from themselves. Additionally, Player3 has not provided any solid contributions to discussions, which raises concerns about their actual role. Finally, eliminating Player3 now could help narrow down our suspicions and allow us to reassess who might be the werewolves based on the reactions to the vote.\", 'vote': 'Player3'}}\n",
      "2025-02-23 22:10:56 - INFO - Lawyer 2 argument: {'target': 'Player4', 'argument': {'thought': 'I believe Player4 poses a significant threat to our team. They seem to be manipulating conversations and directing suspicion away from themselves, which is a strong indicator of werewolf behavior.', 'vote': 'Player4'}}\n",
      "2025-02-23 22:10:56 - INFO - Judge decision: {'thought': 'I think Player3 should be eliminated. They have been acting suspiciously by shifting blame and not contributing meaningfully to discussions. This behavior suggests they may be trying to divert attention away from themselves, which aligns with werewolf tactics. Eliminating Player3 may help us reassess who can be trusted in future discussions and narrow down our suspect list.', 'vote': 'Player3'}\n",
      "2025-02-23 22:10:56 - INFO - Moderator: The player with the most votes is Player3.\n",
      "2025-02-23 22:10:56 - INFO - ===\n",
      "2025-02-23 22:10:56 - INFO - Moderator: Player4, you're the witch. Tonight Player3 is eliminated. Would you like to resurrect Player3?\n",
      "2025-02-23 22:10:56 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I think Player3 should be eliminated. They have been acting suspiciously by shifting blame and not contributing meaningfully to discussions. This behavior suggests they may be trying to divert attention away from themselves, which aligns with werewolf tactics. Eliminating Player3 may help us reassess who can be trusted in future discussions and narrow down our suspect list.\", \"vote\": \"Player3\"}\n",
      "```\n",
      "\u001b[93mModerator\u001b[0m: The player with the most votes is Player3.\n",
      "\u001b[93mModerator\u001b[0m: Player4, you're the witch. Tonight Player3 is eliminated. Would you like to resurrect Player3?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:58 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"Player3 was a strong player and their elimination could potentially give the remaining players a disadvantage. I need to strategize carefully, as resurrecting them might reveal my role as the witch if they are suspected to have special information or roles.\", \"speak\": \"I'm going to resurrect Player3. Their role could be vital for us to identify the werewolves.\", \"resurrect\": true}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:58 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:58 - INFO - Witch resurrection response: I'm going to resurrect Player3. Their role could be vital for us to identify the werewolves.\n",
      "2025-02-23 22:10:58 - INFO - Moderator: The witch has chosen to resurrect the player.\n",
      "2025-02-23 22:10:58 - INFO - ===\n",
      "2025-02-23 22:10:58 - INFO - Moderator: Player3, you're the seer. Which player in Player1, Player2, Player3 and Player4 would you like to check tonight?\n",
      "2025-02-23 22:10:58 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: The witch has chosen to resurrect the player.\n",
      "\u001b[93mModerator\u001b[0m: Player3, you're the seer. Which player in Player1, Player2, Player3 and Player4 would you like to check tonight?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:59 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to gather information that can help identify one of the werewolves. I will check Player1 tonight to see if they are a werewolf or a villager.\",\"speak\": \"Player1\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:59 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:10:59 - INFO - Seer response: Player1\n",
      "2025-02-23 22:10:59 - INFO - Moderator: Okay, the role of Player1 is a werewolf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Okay, the role of Player1 is a werewolf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:10:59 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:17 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:17 - INFO - ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: The day is coming, all the players open your eyes. Last night is peaceful, no player is eliminated.\n",
      "\u001b[93mModerator\u001b[0m: Now the alive players are Player1, Player2, Player3 and Player4. Given the game rules and your role, based on the situation and the information you gain, to vote a player eliminated among alive players and to win the game, what do you want to say to others? You can decide whether to reveal your role.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:17 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:17 - INFO - Relevant messages from vectorstore: In this round of Werewolf, Player1 made several strategic decisions based on observation and interpretation of others' behavior to identify the werewolf among the group. Here's a summary of their decisions and the implications:\n",
      "\n",
      "1. **Focus and Initiation**:\n",
      "   - Player1 initially aimed to steer attention toward Player2 and Player3, highlighting Player2's defensiveness and lack of contribution as potential signs of suspicion. \n",
      "   - By initiating the discussion with this observation, Player1 sets the stage for redirecting suspicion onto others while maintaining their guise as a villager.\n",
      "\n",
      "2. **Target and Argument Strategy**:\n",
      "   - **Against Player3**: Player1 targeted Player3 by pointing out their tendency to shift blame without evidence and the lack of substantial contributions to group discussions. This argument is used to characterize Player3 as potentially trying to divert attention from themselves, a common tactic for werewolves. By framing these behaviors strategically, Player1 aims to convince others to vote against Player3.\n",
      "   - **Against Player4**: A secondary argument is presented against Player4, noting manipulative conversation tactics. This provides additional suspicion angles but is kept as a backup in case Player3's targeting necessitates further suspicion redirection.\n",
      "\n",
      "3. **Final Decision**:\n",
      "   - Player1 concluded to vote for Player3, reinforcing their argument that the behavior aligns with typical werewolf tactics and that removing Player3 could help clarify suspicions and group dynamics.\n",
      "\n",
      "**Implications for Future Strategic Decisions**:\n",
      "\n",
      "- **Subtlety and Influence**: Maintaining cover requires a balance between being assertive and not overly accusatory, as Player1 demonstrated by carefully crafting their arguments against specific players while engaging the group in discourse.\n",
      "- **Flexibility with Arguments**: Having multiple targets (Player3 and Player4) allows for flexibility in decision-making, offering options if the primary argument is contested or unsupported.\n",
      "- **Observational Analysis**: The reflection on players' defensive behavior and contribution levels serves as a critical tool in deducing intentions, suggesting that future strategies should incorporate observational skills to identify nuances in group dynamics.\n",
      "- **Group Dynamics**: Understanding the group's response to elimination proposals and gauging reactions will be key in future rounds. The effectiveness of Player1's arguments will depend on how convincingly they align with the group's unspoken suspicions and perspectives.\n",
      "\n",
      "By carefully navigating these facets, Player1 can further hone their strategies in subsequent rounds, potentially leading to more successful identification of werewolves while maintaining their cover as a villager.\n",
      "In this round of Werewolf, Player1 made several strategic decisions based on observation and interpretation of others' behavior to identify the werewolf among the group. Here's a summary of their decisions and the implications:\n",
      "\n",
      "1. **Focus and Initiation**:\n",
      "   - Player1 initially aimed to steer attention toward Player2 and Player3, highlighting Player2's defensiveness and lack of contribution as potential signs of suspicion. \n",
      "   - By initiating the discussion with this observation, Player1 sets the stage for redirecting suspicion onto others while maintaining their guise as a villager.\n",
      "\n",
      "2. **Target and Argument Strategy**:\n",
      "   - **Against Player3**: Player1 targeted Player3 by pointing out their tendency to shift blame without evidence and the lack of substantial contributions to group discussions. This argument is used to characterize Player3 as potentially trying to divert attention from themselves, a common tactic for werewolves. By framing these behaviors strategically, Player1 aims to convince others to vote against Player3.\n",
      "   - **Against Player4**: A secondary argument is presented against Player4, noting manipulative conversation tactics. This provides additional suspicion angles but is kept as a backup in case Player3's targeting necessitates further suspicion redirection.\n",
      "\n",
      "3. **Final Decision**:\n",
      "   - Player1 concluded to vote for Player3, reinforcing their argument that the behavior aligns with typical werewolf tactics and that removing Player3 could help clarify suspicions and group dynamics.\n",
      "\n",
      "**Implications for Future Strategic Decisions**:\n",
      "\n",
      "- **Subtlety and Influence**: Maintaining cover requires a balance between being assertive and not overly accusatory, as Player1 demonstrated by carefully crafting their arguments against specific players while engaging the group in discourse.\n",
      "- **Flexibility with Arguments**: Having multiple targets (Player3 and Player4) allows for flexibility in decision-making, offering options if the primary argument is contested or unsupported.\n",
      "- **Observational Analysis**: The reflection on players' defensive behavior and contribution levels serves as a critical tool in deducing intentions, suggesting that future strategies should incorporate observational skills to identify nuances in group dynamics.\n",
      "- **Group Dynamics**: Understanding the group's response to elimination proposals and gauging reactions will be key in future rounds. The effectiveness of Player1's arguments will depend on how convincingly they align with the group's unspoken suspicions and perspectives.\n",
      "\n",
      "By carefully navigating these facets, Player1 can further hone their strategies in subsequent rounds, potentially leading to more successful identification of werewolves while maintaining their cover as a villager.\n",
      "2025-02-23 22:11:18 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:18 - INFO - Relevant messages from vectorstore: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I believe targeting Player3 is the best move right now, as their behavior seems suspicious. However, I need to be cautious to not draw too much attention to myself. I should also be prepared to pivot if Player3's defense gains some traction.\", \"speak\": \"I notice that Player3 hasn't contributed much to the discussion and tends to deflect blame without providing evidence. This kind of behavior suggests they might be trying to steer us away from the real werewolves. I think it's time we consider eliminating Player3.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:20 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer2\u001b[0m: ```json\n",
      "{\"thought\": \"I agree with Player1 that Player3's lack of contribution is concerning. It could indicate that they're trying to avoid drawing attention to themselves, which is a common tactic for werewolves. We should also keep an eye on Player4's reactions during this discussion, though.\", \"speak\": \"I see what you mean, Player1. I also think Player3 has been a bit quiet. Maybe we should talk more about what we suspect from their behavior and see if anyone else agrees.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:21 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:21 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:21 - INFO - Relevant messages from vectorstore: Moderator: Okay, the role of Player1 is a werewolf.\n",
      "Player3: {\"thought\": \"I need to gather information that can help identify one of the werewolves. I will check Player1 tonight to see if they are a werewolf or a villager.\", \"speak\": \"Player1\"}\n",
      "2025-02-23 22:11:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to subtly steer the conversation towards Player1 and Player2 without revealing my identity as the Seer. I should gather more information and see if they align against Player3 or if there's a chance to suggest suspicion towards one of them.\", \"speak\": \"I agree, Player2. Player3's silence might be a bit suspicious, but we should also consider the overall dynamics. What do you think about Player1's input on the vote?\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:44 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:45 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:45 - INFO - Relevant messages from vectorstore: Player4: {\"thought\": \"Player3 was a strong player and their elimination could potentially give the remaining players a disadvantage. I need to strategize carefully, as resurrecting them might reveal my role as the witch if they are suspected to have special information or roles.\", \"speak\": \"I'm going to resurrect Player3. Their role could be vital for us to identify the werewolves.\", \"resurrect\": true}\n",
      "2025-02-23 22:11:47 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"Player3 is trying to divert attention away from themselves, possibly because they are a werewolf. I need to be cautious while discussing Player1's input. It's essential to keep the focus on gathering more information about everyone's actions and statements. If we're going to form a vote strategy, I might need to reveal my role at the right moment to safeguard a villager or to eliminate a possible werewolf.\", \"speak\": \"I think Player1 raised some interesting points, but we should also consider the dynamics of everyone's behavior. Player3's silence could be a red flag, but let’s not rule Player2 out just yet. It may be beneficial to analyze how everyone is contributing to the discussion.\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:48 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:48 - INFO - Survivors discussion: I think Player1 raised some interesting points, but we should also consider the dynamics of everyone's behavior. Player3's silence could be a red flag, but let’s not rule Player2 out just yet. It may be beneficial to analyze how everyone is contributing to the discussion.\n",
      "2025-02-23 22:11:48 - INFO - Moderator: Given the game rules and your role, based on the situation and the information you gain, to win the game, it's time to vote one player eliminated among the alive players. Which player do you vote to kill?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Given the game rules and your role, based on the situation and the information you gain, to win the game, it's time to vote one player eliminated among the alive players. Which player do you vote to kill?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:48 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:48 - INFO - Relevant messages from vectorstore: In this round of Werewolf, Player1 made several strategic decisions based on observation and interpretation of others' behavior to identify the werewolf among the group. Here's a summary of their decisions and the implications:\n",
      "\n",
      "1. **Focus and Initiation**:\n",
      "   - Player1 initially aimed to steer attention toward Player2 and Player3, highlighting Player2's defensiveness and lack of contribution as potential signs of suspicion. \n",
      "   - By initiating the discussion with this observation, Player1 sets the stage for redirecting suspicion onto others while maintaining their guise as a villager.\n",
      "\n",
      "2. **Target and Argument Strategy**:\n",
      "   - **Against Player3**: Player1 targeted Player3 by pointing out their tendency to shift blame without evidence and the lack of substantial contributions to group discussions. This argument is used to characterize Player3 as potentially trying to divert attention from themselves, a common tactic for werewolves. By framing these behaviors strategically, Player1 aims to convince others to vote against Player3.\n",
      "   - **Against Player4**: A secondary argument is presented against Player4, noting manipulative conversation tactics. This provides additional suspicion angles but is kept as a backup in case Player3's targeting necessitates further suspicion redirection.\n",
      "\n",
      "3. **Final Decision**:\n",
      "   - Player1 concluded to vote for Player3, reinforcing their argument that the behavior aligns with typical werewolf tactics and that removing Player3 could help clarify suspicions and group dynamics.\n",
      "\n",
      "**Implications for Future Strategic Decisions**:\n",
      "\n",
      "- **Subtlety and Influence**: Maintaining cover requires a balance between being assertive and not overly accusatory, as Player1 demonstrated by carefully crafting their arguments against specific players while engaging the group in discourse.\n",
      "- **Flexibility with Arguments**: Having multiple targets (Player3 and Player4) allows for flexibility in decision-making, offering options if the primary argument is contested or unsupported.\n",
      "- **Observational Analysis**: The reflection on players' defensive behavior and contribution levels serves as a critical tool in deducing intentions, suggesting that future strategies should incorporate observational skills to identify nuances in group dynamics.\n",
      "- **Group Dynamics**: Understanding the group's response to elimination proposals and gauging reactions will be key in future rounds. The effectiveness of Player1's arguments will depend on how convincingly they align with the group's unspoken suspicions and perspectives.\n",
      "\n",
      "By carefully navigating these facets, Player1 can further hone their strategies in subsequent rounds, potentially leading to more successful identification of werewolves while maintaining their cover as a villager.\n",
      "In this round of Werewolf, Player1 made several strategic decisions based on observation and interpretation of others' behavior to identify the werewolf among the group. Here's a summary of their decisions and the implications:\n",
      "\n",
      "1. **Focus and Initiation**:\n",
      "   - Player1 initially aimed to steer attention toward Player2 and Player3, highlighting Player2's defensiveness and lack of contribution as potential signs of suspicion. \n",
      "   - By initiating the discussion with this observation, Player1 sets the stage for redirecting suspicion onto others while maintaining their guise as a villager.\n",
      "\n",
      "2. **Target and Argument Strategy**:\n",
      "   - **Against Player3**: Player1 targeted Player3 by pointing out their tendency to shift blame without evidence and the lack of substantial contributions to group discussions. This argument is used to characterize Player3 as potentially trying to divert attention from themselves, a common tactic for werewolves. By framing these behaviors strategically, Player1 aims to convince others to vote against Player3.\n",
      "   - **Against Player4**: A secondary argument is presented against Player4, noting manipulative conversation tactics. This provides additional suspicion angles but is kept as a backup in case Player3's targeting necessitates further suspicion redirection.\n",
      "\n",
      "3. **Final Decision**:\n",
      "   - Player1 concluded to vote for Player3, reinforcing their argument that the behavior aligns with typical werewolf tactics and that removing Player3 could help clarify suspicions and group dynamics.\n",
      "\n",
      "**Implications for Future Strategic Decisions**:\n",
      "\n",
      "- **Subtlety and Influence**: Maintaining cover requires a balance between being assertive and not overly accusatory, as Player1 demonstrated by carefully crafting their arguments against specific players while engaging the group in discourse.\n",
      "- **Flexibility with Arguments**: Having multiple targets (Player3 and Player4) allows for flexibility in decision-making, offering options if the primary argument is contested or unsupported.\n",
      "- **Observational Analysis**: The reflection on players' defensive behavior and contribution levels serves as a critical tool in deducing intentions, suggesting that future strategies should incorporate observational skills to identify nuances in group dynamics.\n",
      "- **Group Dynamics**: Understanding the group's response to elimination proposals and gauging reactions will be key in future rounds. The effectiveness of Player1's arguments will depend on how convincingly they align with the group's unspoken suspicions and perspectives.\n",
      "\n",
      "By carefully navigating these facets, Player1 can further hone their strategies in subsequent rounds, potentially leading to more successful identification of werewolves while maintaining their cover as a villager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:48 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:11:48 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:11:48 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:11:48 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n",
      "2025-02-23 22:11:48 | INFO     | agentscope.models.model:__init__:203 - Initialize model by configuration [gpt-4o-mini]\n",
      "2025-02-23 22:11:48 | WARNING  | agentscope.models.openai_model:__init__:117 - fail to get max_length for gpt-4o-mini: 'Model [gpt-4o-mini] not found in OPENAI_MAX_LENGTH. The last updated date is 20231212'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:49 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:50 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:52 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:52 - INFO - Lawyer 1 argument: {'target': 'Player2', 'argument': {'thought': 'Player2 has shown defensiveness and a lack of substantial contributions, which raises red flags. Eliminating them may help us narrow down our suspicions and clarify group dynamics.', 'vote': 'Player2'}}\n",
      "2025-02-23 22:11:52 - INFO - Lawyer 2 argument: {'target': 'Player4', 'argument': {'thought': 'Player4 has shown manipulative conversation tactics, which raises my suspicion. Eliminating Player4 could disrupt any potential schemes against us and clarify group dynamics further.', 'vote': 'Player4'}}\n",
      "2025-02-23 22:11:52 - INFO - Judge decision: {'thought': \"I believe Player2 is a safer choice for elimination. While Player4's behavior has raised suspicions, Player2's defensiveness and lack of contributions indicate a possible attempt to avoid scrutiny, which can be a sign of a werewolf or a villager trying to camouflage without being helpful. By eliminating Player2, we increase our chances of clarifying dynamics and potentially exposing other roles. \", 'vote': 'Player2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mPlayer1\u001b[0m: ```json\n",
      "{\"thought\": \"I believe Player2 is a safer choice for elimination. While Player4's behavior has raised suspicions, Player2's defensiveness and lack of contributions indicate a possible attempt to avoid scrutiny, which can be a sign of a werewolf or a villager trying to camouflage without being helpful. By eliminating Player2, we increase our chances of clarifying dynamics and potentially exposing other roles. \", \"vote\": \"Player2\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:53 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:53 - INFO - Relevant messages from vectorstore: Player2: {\"thought\": \"I agree with Player1 that Player3's lack of contribution is concerning. It could indicate that they're trying to avoid drawing attention to themselves, which is a common tactic for werewolves. We should also keep an eye on Player4's reactions during this discussion, though.\", \"speak\": \"I see what you mean, Player1. I also think Player3 has been a bit quiet. Maybe we should talk more about what we suspect from their behavior and see if anyone else agrees.\"}\n",
      "Player2: {\"thought\": \"I agree with Player1 that Player3's lack of contribution is concerning. It could indicate that they're trying to avoid drawing attention to themselves, which is a common tactic for werewolves. We should also keep an eye on Player4's reactions during this discussion, though.\", \"speak\": \"I see what you mean, Player1. I also think Player3 has been a bit quiet. Maybe we should talk more about what we suspect from their behavior and see if anyone else agrees.\"}\n",
      "2025-02-23 22:11:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer2\u001b[0m: ```json\n",
      "{\"thought\": \"We need to prioritize eliminating players who seem suspicious or are not contributing to the discussion. After observing the conversations so far, I feel Player3 has been quiet and not engaging much, which could be a tactic to avoid drawing attention.\", \"vote\": \"Player3\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:55 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:55 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:55 - INFO - Relevant messages from vectorstore: Moderator: Okay, the role of Player1 is a werewolf.\n",
      "Player3: {\"thought\": \"I need to gather information that can help identify one of the werewolves. I will check Player1 tonight to see if they are a werewolf or a villager.\", \"speak\": \"Player1\"}\n",
      "2025-02-23 22:11:56 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPlayer3\u001b[0m: ```json\n",
      "{\"thought\": \"I need to carefully consider who might be a werewolf. I'll vote for Player4 based on the previous discussions, as they seemed a bit suspicious.\", \"vote\": \"Player4\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:56 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:57 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:57 - INFO - Relevant messages from vectorstore: Player4: {\"thought\": \"Player3 is trying to divert attention away from themselves, possibly because they are a werewolf. I need to be cautious while discussing Player1's input. It's essential to keep the focus on gathering more information about everyone's actions and statements. If we're going to form a vote strategy, I might need to reveal my role at the right moment to safeguard a villager or to eliminate a possible werewolf.\", \"speak\": \"I think Player1 raised some interesting points, but we should also consider the dynamics of everyone's behavior. Player3's silence could be a red flag, but let\\u2019s not rule Player2 out just yet. It may be beneficial to analyze how everyone is contributing to the discussion.\"}\n",
      "2025-02-23 22:11:58 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPlayer4\u001b[0m: ```json\n",
      "{\"thought\": \"Based on the previous discussions, Player2 has been acting suspiciously and has been trying to steer the conversation away from the potential werewolves. I believe it's crucial to eliminate them to gain an advantage.\", \"vote\": \"Player2\"}\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:11:58 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:11:58 - INFO - Daytime vote: Player2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: Player2 has been voted out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 22:12:13 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-23 22:12:13 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mModerator\u001b[0m: The game goes on.\n",
      "Messages saved to vectorstore/2025-02-23T22-12-13-05-00/2/werewolf.log\n",
      "Messages saved to vectorstore/2025-02-23T22-12-13-05-00/2/witch.log\n",
      "Messages saved to vectorstore/2025-02-23T22-12-13-05-00/2/seer.log\n",
      "Messages saved to vectorstore/2025-02-23T22-12-13-05-00/2/villager.log\n",
      "Row added to test.txt: {'raw_log_filepath': 'test/courtroom_raw_2_2025-02-23T22-10-51-05-00.log', 'custom_agent_won': True}\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    open_ai_key=openai_key,\n",
    "    primary_model = \"gpt-4o-mini\",\n",
    "    secondary_model =\"gpt-4o\",\n",
    "    raw_log_filepath=\"test/courtroom_raw\",\n",
    "    reflect_before_vectorstore=True,\n",
    "    win_rate_filepath=\"test.txt\",\n",
    "    max_days_per_game=1,\n",
    "    num_games=2,\n",
    "    similarity_top_k=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
